{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-13\n",
    "\n",
    "Design of ResNet-18 Architecture and Training the model with CIFAR-10 to target a 90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Normalization\n",
    "\n",
    "Image was loaded into NumPy Arrays and normalized better regularization. Other regularization techniques like ZCA whitening was used and the accuracy was found to be 87.73% over 87.01% with simple image normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sambit/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-28.404232 35.503895\n",
      "-38.652294 33.47046\n",
      "(50000, 32, 32, 3) (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import utils \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(trainx, trainy), (testx, testy) = cifar10.load_data()\n",
    "ntrain, rows, cols, ch =  trainx.shape\n",
    "ntest, _, _, _         =  testx.shape\n",
    "ncls = len(np.unique(trainy))\n",
    "print(ncls)\n",
    "\n",
    "trainx = trainx.astype('float32') / 255\n",
    "testx = testx.astype('float32') / 255\n",
    "\n",
    "trainx_mean = trainx.mean(axis=0)\n",
    "trainx_std  = trainx.std(axis=0)\n",
    "\n",
    "#print(trainx_mean, trainx_std)\n",
    "\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "datagen.fit(trainx)\n",
    "\n",
    "iterate = datagen.flow(trainx, trainy, batch_size=len(trainx), shuffle=False)\n",
    "\n",
    "trainx, trainy = iterate.next()\n",
    "\n",
    "iterate = datagen.flow(testx, testy, batch_size=len(testx), shuffle=False)\n",
    "\n",
    "testx, testy = iterate.next()\n",
    "\n",
    "# trainx -= trainx_mean\n",
    "# trainx /= trainx_std\n",
    "\n",
    "# testx -= trainx_mean\n",
    "# testx /= trainx_std\n",
    "\n",
    "trainX, trainY = trainx, utils.to_categorical(trainy)\n",
    "testX,  testY  = testx,  utils.to_categorical(testy)\n",
    "\n",
    "min_pix, max_pix = trainX.min(), trainX.max()\n",
    "\n",
    "print(min_pix, max_pix)\n",
    "print(testX.min(), testX.max())\n",
    "\n",
    "print(trainX.shape, trainY.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "WT_DECAY   = 1e-4\n",
    "LRFNEPOCH  = 4\n",
    "MOMENTUM   = 0.9\n",
    "EPOCHS     = 300\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Model Design\n",
    "\n",
    "ResNet Architecture is composed of the following:\n",
    "\n",
    "1. Conv2D(7x7)\n",
    "2. Followed by MaxPooling\n",
    "3. Followed by Deep ResNet Blocks\n",
    "4. Each ResNetBlock has ResNet Units\n",
    "5. Each ResNet Units contains convolution blocks\n",
    "6. Each Convolution block is a mix of BatchNormalization, Activation and Convolution with strides\n",
    "7. The width of the layers increases exponentially at a ratio of 2 (64, 128, 256, 512)\n",
    "8. Fully pre-activated ResNet blocks are used for convolution\n",
    "9. The order of BatchNormalization, Activation, Followed by Convolution is carried out based on the efficiency recommendations from the DavidNet 8 papers.\n",
    "10. The strides were modified with MaxPooling but the same did not lead to additional benefits as such. \n",
    "\n",
    "The Blocks were such designed such that ResNet-9 as well as ResNet-18 can be configured using the same building blocks and are presented below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation, MaxPool2D\n",
    "from tensorflow.keras.layers import add, Input, Dense, Flatten, GlobalAvgPool2D\n",
    "from tensorflow.keras.initializers import zeros\n",
    "\n",
    "\n",
    "def ResConv(x, kernel=(3, 3), depth=32, maxpool=False):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(depth, kernel, strides=(maxpool and 2 or 1), padding='same', use_bias=False)(x)\n",
    "    return x\n",
    "\n",
    "def ResUnit(x, depth=32, maxpool=False):\n",
    "    x = ResConv(x, depth=depth, maxpool=maxpool)\n",
    "    x = ResConv(x, depth=depth)\n",
    "    return x\n",
    "    \n",
    "def ResNetBlock(x, nunit, depth=32, maxpool=False, name=\"Block-1\"):\n",
    "    assert nunit > 0, \"Ensure there are at least 1 unit in the ResNet Block\"\n",
    "    nunit -= 1\n",
    "    if maxpool:\n",
    "        xskip = Conv2D(depth, (1, 1), strides=2, use_bias=False)(x)\n",
    "    else: \n",
    "        xskip = x\n",
    "    x = add([ResUnit(x, depth=depth, maxpool=maxpool), xskip])\n",
    "    if nunit >= 1:\n",
    "        nunit -= 1\n",
    "        for i in range(nunit):\n",
    "            x = add([ResUnit(x, depth=depth), x])\n",
    "        x = add([ResUnit(x, depth=depth), x], name=name)\n",
    "    return x\n",
    "        \n",
    "def ResNet18(x):\n",
    "    x = Conv2D(64, (7, 7), strides=2, padding='same', use_bias=False)(x)\n",
    "    x = MaxPool2D((3, 3),  strides=2, padding='same')(x)\n",
    "    \n",
    "    nunits   = (2, 2, 2, 2)\n",
    "    maxpools = (False, True, True, True)\n",
    "    depths   = (64, 128, 256, 512)\n",
    "    \n",
    "    for i in range(4):\n",
    "        x = ResNetBlock(x, nunits[i], depth=depths[i], maxpool=maxpools[i], name=\"Block-\"+str(i))\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    return x\n",
    "\n",
    "def ResNet9(x):\n",
    "    x = Conv2D(64, (7, 7), strides=2, padding='same', use_bias=False)(x)\n",
    "    x = MaxPool2D((3, 3),  strides=2, padding='same')(x)\n",
    "    \n",
    "    nunits   = (2, 3, 2)\n",
    "    maxpools = (False, True, True)\n",
    "    depths   = (64, 128, 256)\n",
    "    \n",
    "    for i in range(3):\n",
    "        x = ResNetBlock(x, nunits[i], depth=depths[i], maxpool=maxpools[i], name=\"Block-\"+str(i))\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers and Training\n",
    "\n",
    "1. SGD with momentum was used for used for training. \n",
    "2. Custom L2 regularizer was designed rather than using the standard Keras layers based model to ensure the L2 regularizer can be controlled dynamically. The experiments there were not very successful in improving model accuracy significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 64)   9408        Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 8, 64)     0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 8, 64)     256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 8, 8, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 64)     36864       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 64)     36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 8, 64)     0           conv2d_2[0][0]                   \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 64)     256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 64)     36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 64)     36864       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Block-0 (Add)                   (None, 8, 8, 64)     0           conv2d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         Block-0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 128)    73728       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 4, 128)    512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 4, 4, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 128)    147456      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 4, 4, 128)    8192        Block-0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 4, 128)    0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 4, 128)    512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4, 4, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    147456      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4, 4, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 128)    147456      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Block-1 (Add)                   (None, 4, 4, 128)    0           conv2d_9[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 128)    512         Block-1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 256)    294912      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2, 2, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 2, 2, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 256)    589824      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 2, 256)    32768       Block-1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2, 2, 256)    0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 256)    1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 2, 2, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 2, 2, 256)    589824      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 2, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2, 2, 256)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 2, 2, 256)    589824      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Block-2 (Add)                   (None, 2, 2, 256)    0           conv2d_14[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2, 2, 256)    1024        Block-2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 2, 2, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 1, 1, 512)    1179648     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 1, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 1, 512)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 1, 1, 512)    2359296     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1, 1, 512)    131072      Block-2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 1, 512)    0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 1, 512)    2048        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1, 1, 512)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 1, 512)    2359296     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1, 1, 512)    2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1, 1, 512)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 1, 1, 512)    2359296     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Block-3 (Add)                   (None, 1, 1, 512)    0           conv2d_19[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           Block-3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           5120        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 11,185,600\n",
      "Trainable params: 11,178,816\n",
      "Non-trainable params: 6,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def l2_weights(model):\n",
    "    l2 = 0\n",
    "    for layer in model.layers: \n",
    "        wt = layer.weights\n",
    "        if len(wt) > 0:\n",
    "            l2 += K.sum(K.pow(wt, 2))\n",
    "    return l2\n",
    "\n",
    "def reg_loss(model):\n",
    "    def rloss(y_true, y_pred):\n",
    "        return model.l2_reg*l2_weights(model)\n",
    "    return rloss\n",
    "\n",
    "def loss_with_regularization(model):\n",
    "    def loss(y_true, y_pred):\n",
    "        return categorical_crossentropy(y_true, y_pred) + reg_loss(model)(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def model_init(optimizer=None):\n",
    "    xin = Input(shape=(32, 32, 3), name=\"Input\")\n",
    "    x = ResNet18(xin)\n",
    "    x = Dense(ncls, use_bias=False)(x)\n",
    "    y = Activation('softmax')(x)\n",
    "    model = Model(xin, y)\n",
    "    model.l2_reg = K.variable(value=WT_DECAY, dtype='float32', name='reg_loss')\n",
    "    if optimizer is None:\n",
    "        optimizer = SGD(lr=1e-3, momentum=MOMENTUM, nesterov=True)\n",
    "    model.compile(optimizer=optimizer, loss=loss_with_regularization(model), metrics=['acc', reg_loss(model)])\n",
    "    return model\n",
    "\n",
    "model = model_init()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Regularization\n",
    "\n",
    "CIFAR-10 with ResNet-18 may require some extreme level of regularization due to the following reasons:\n",
    "\n",
    "1. CIFAR-10 has 50000x32x32x3 data points which is essentially a 150 million data points.\n",
    "2. ResNet-18 has 11.2 million parameters. Purely linear algebra based assumption would mean 14 pixel for each parameter identification which is quite an underconstraint problem. \n",
    "3. Hence, the following image augmentation was carried out:\n",
    "   a. ZCA whitening of the input and test dataset\n",
    "   b. Image translation of 4 pixels in all sides with constant fill mode of zero ensuring the same effect as padding and random cropping\n",
    "   c. Random horizontal flip \n",
    "   d. Cutout with 8x8 pixel values. \n",
    "4. Effetively, this ensures the training is exposed to a new image every run. This is as good as saying the network was trained on 50000x(nepoch=100) number of images increasing the training set dramatically. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = 8 #int(np.sqrt(s / r))\n",
    "            h = 8 #int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = 0.0 #np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        fill_mode = 'constant',\n",
    "        cval=0,\n",
    "        width_shift_range=4,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=4,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        preprocessing_function=get_random_eraser(v_l=min_pix, v_h=max_pix, pixel_level=False)\n",
    ")\n",
    "datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Optimal Learning Rate\n",
    "\n",
    "Optimal maximum learning rate is required for OneCycleLR or CyclicLR to ideally find the right learning rate. The right learning rate ensures the spurious minimas are avoided or higher LRs jumps over the narrow minimas and drops on flatter minimas. L2 regulararisation flattens the loss function by adding a quadratic potential function. The weight decay($\\alpha$), momentum($\\rho$) and LR($\\lambda$) together play an interwined role. However, with a quadratic weak solution present in the function, the following relationship can be assumed:\n",
    "\n",
    "$$ \\frac{\\alpha\\lambda}{1-\\rho} = \\frac{V}{W} $$\n",
    "\n",
    "Once option can be to keep these values a constant and lower the constant as there is no significant reduction is loss. The complete experiment could not be completed as part of this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "class LR_Finder(Callback):\n",
    "    \n",
    "    def __init__(self, start_lr=1e-5, end_lr=10, step_size=None, beta=.98):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.start_lr = start_lr\n",
    "        self.end_lr = end_lr\n",
    "        self.step_size = step_size\n",
    "        self.beta = beta\n",
    "        self.lr_mult = (end_lr/start_lr)**(1/step_size)\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.best_loss = 1e9\n",
    "        self.avg_loss = 0\n",
    "        self.losses, self.smoothed_losses, self.lrs, self.iterations = [], [], [], []\n",
    "        self.iteration = 0\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.start_lr)\n",
    "        \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        self.iteration += 1\n",
    "        \n",
    "        self.avg_loss = self.beta * self.avg_loss + (1 - self.beta) * loss\n",
    "        smoothed_loss = self.avg_loss / (1 - self.beta**self.iteration)\n",
    "        \n",
    "        # Check if the loss is not exploding\n",
    "        if self.iteration > 1 and smoothed_loss > self.best_loss * 1000:\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        if smoothed_loss < self.best_loss or self.iteration==1:\n",
    "            self.best_loss = smoothed_loss\n",
    "        \n",
    "        lr = self.start_lr * (self.lr_mult**self.iteration)\n",
    "        \n",
    "        self.losses.append(loss)\n",
    "        self.smoothed_losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "        self.iterations.append(self.iteration)\n",
    "        \n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, lr)  \n",
    "        \n",
    "    def plot_lr(self):\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Learning rate')\n",
    "        plt.plot(self.iterations, self.lrs)\n",
    "        \n",
    "    def plot(self, n_skip=1):\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Learning rate (log scale)')\n",
    "        plt.plot(self.lrs[n_skip:-5], self.losses[n_skip:-5])\n",
    "        plt.xscale('log')\n",
    "        \n",
    "    def plot_smoothed_loss(self, n_skip=10):\n",
    "        plt.ylabel('Smoothed Losses')\n",
    "        plt.xlabel('Learning rate (log scale)')\n",
    "        plt.plot(self.lrs[n_skip:-5], self.smoothed_losses[n_skip:-5])\n",
    "        plt.xscale('log')\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        plt.ylabel('Losses')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.plot(self.iterations[10:], self.losses[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum LR\n",
    "\n",
    "From the below graphs it can be seen 0.08 is the borderline LR for OneCycleLR but for CyclicLR 0.01 or 0.02 may be preferred. Cyclic LR requires the LRs to be perfectly within the stable zone of LR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:From /home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "98/98 [==============================] - 22s 227ms/step - loss: 3.4329 - acc: 0.1456 - rloss: 0.9931 - val_loss: 3.1872 - val_acc: 0.1665 - val_rloss: 0.9454\n",
      "Epoch 2/4\n",
      "98/98 [==============================] - 15s 158ms/step - loss: 2.9922 - acc: 0.2622 - rloss: 0.9487 - val_loss: 2.7230 - val_acc: 0.3894 - val_rloss: 0.9537\n",
      "Epoch 3/4\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 3.2338 - acc: 0.4473 - rloss: 0.9481 - val_loss: 596451339.2000 - val_acc: 0.1000 - val_rloss: 1.0677\n",
      "Epoch 4/4\n",
      " 2/98 [..............................] - ETA: 7s - loss: 18491790566908084.0000 - acc: 0.0967 - rloss: 20877.9219"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_init()\n",
    "lr_finder = LR_Finder(start_lr=1e-4, end_lr=1, step_size=np.ceil(trainX.shape[0]/(BATCH_SIZE/LRFNEPOCH)))\n",
    "model.fit_generator(datagen.flow(trainX, trainY, batch_size = BATCH_SIZE),\n",
    "                    epochs=LRFNEPOCH,\n",
    "                    validation_data = (testX, testY), verbose=1,\n",
    "                    callbacks=[lr_finder])\n",
    "lr_finder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot_smoothed_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Run\n",
    "\n",
    "One Cycle Run was used on a 100 epoch scale. Although, a controlled iterative approach to control LR, momentum and weight decay was attempted the results were not very promising. The network was kind of stopping to approaching the goal. Hence, final run had commented out those parts. However, one can think of achieving a OneCycleLR to get to a stable location and reduce L2 regularization and control other parameters with lesser LR values to get to more deeper minimas. \n",
    "\n",
    "The final result was: 87.73 % \n",
    "\n",
    "There is possibility of a better accuracy considering the model accuracy has an upward trend suggesting there is a possibility of achieving higher accuracy beyond 100 epochs. However, OneCycleLR beyond 100 epochs did not achieve better accuracy. There was a run with 50 epochs as well which gave a 86.50% accuracy. 30 epoch OneCycleLR was about 84% validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.2756 - acc: 0.1957 - rloss: 0.9929\n",
      "Epoch 00001: val_acc improved from -inf to 0.27550, saving model to model.001-0.2755.hdf5\n",
      "lr: 0.0041, rho: 0.9924, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 25s 257ms/step - loss: 3.2707 - acc: 0.1972 - rloss: 0.9924 - val_loss: 3.0230 - val_acc: 0.2755 - val_rloss: 0.9458\n",
      "Epoch 2/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.5300 - acc: 0.4321 - rloss: 0.9401\n",
      "Epoch 00002: val_acc improved from 0.27550 to 0.48930, saving model to model.002-0.4893.hdf5\n",
      "lr: 0.0080, rho: 0.9849, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 161ms/step - loss: 2.5283 - acc: 0.4327 - rloss: 0.9402 - val_loss: 2.4198 - val_acc: 0.4893 - val_rloss: 0.9407\n",
      "Epoch 3/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.1834 - acc: 0.5618 - rloss: 0.9491\n",
      "Epoch 00003: val_acc improved from 0.48930 to 0.60350, saving model to model.003-0.6035.hdf5\n",
      "lr: 0.0120, rho: 0.9774, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 2.1829 - acc: 0.5620 - rloss: 0.9493 - val_loss: 2.0915 - val_acc: 0.6035 - val_rloss: 0.9600\n",
      "Epoch 4/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.0312 - acc: 0.6261 - rloss: 0.9740\n",
      "Epoch 00004: val_acc improved from 0.60350 to 0.62420, saving model to model.004-0.6242.hdf5\n",
      "lr: 0.0160, rho: 0.9699, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 2.0314 - acc: 0.6261 - rloss: 0.9741 - val_loss: 2.0571 - val_acc: 0.6242 - val_rloss: 0.9882\n",
      "Epoch 5/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.9495 - acc: 0.6653 - rloss: 0.9998\n",
      "Epoch 00005: val_acc improved from 0.62420 to 0.66760, saving model to model.005-0.6676.hdf5\n",
      "lr: 0.0200, rho: 0.9624, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 173ms/step - loss: 1.9500 - acc: 0.6651 - rloss: 0.9999 - val_loss: 1.9934 - val_acc: 0.6676 - val_rloss: 1.0123\n",
      "Epoch 6/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8948 - acc: 0.6907 - rloss: 1.0195\n",
      "Epoch 00006: val_acc improved from 0.66760 to 0.70630, saving model to model.006-0.7063.hdf5\n",
      "lr: 0.0240, rho: 0.9549, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 1.8942 - acc: 0.6906 - rloss: 1.0196 - val_loss: 1.8937 - val_acc: 0.7063 - val_rloss: 1.0275\n",
      "Epoch 7/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8520 - acc: 0.7138 - rloss: 1.0358\n",
      "Epoch 00007: val_acc improved from 0.70630 to 0.71670, saving model to model.007-0.7167.hdf5\n",
      "lr: 0.0280, rho: 0.9475, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 1.8528 - acc: 0.7134 - rloss: 1.0359 - val_loss: 1.8807 - val_acc: 0.7167 - val_rloss: 1.0448\n",
      "Epoch 8/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.8165 - acc: 0.7302 - rloss: 1.0498\n",
      "Epoch 00008: val_acc did not improve from 0.71670\n",
      "lr: 0.0320, rho: 0.9400, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 1.8168 - acc: 0.7302 - rloss: 1.0498 - val_loss: 1.9531 - val_acc: 0.6997 - val_rloss: 1.0536\n",
      "Epoch 9/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7815 - acc: 0.7450 - rloss: 1.0592\n",
      "Epoch 00009: val_acc improved from 0.71670 to 0.75900, saving model to model.009-0.7590.hdf5\n",
      "lr: 0.0360, rho: 0.9325, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 1.7816 - acc: 0.7449 - rloss: 1.0593 - val_loss: 1.7642 - val_acc: 0.7590 - val_rloss: 1.0634\n",
      "Epoch 10/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7590 - acc: 0.7553 - rloss: 1.0651\n",
      "Epoch 00010: val_acc improved from 0.75900 to 0.76620, saving model to model.010-0.7662.hdf5\n",
      "lr: 0.0400, rho: 0.9250, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 1.7584 - acc: 0.7556 - rloss: 1.0651 - val_loss: 1.7497 - val_acc: 0.7662 - val_rloss: 1.0691\n",
      "Epoch 11/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7297 - acc: 0.7687 - rloss: 1.0714\n",
      "Epoch 00011: val_acc did not improve from 0.76620\n",
      "lr: 0.0440, rho: 0.9175, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 1.7299 - acc: 0.7686 - rloss: 1.0714 - val_loss: 1.8629 - val_acc: 0.7383 - val_rloss: 1.0745\n",
      "Epoch 12/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7143 - acc: 0.7761 - rloss: 1.0780\n",
      "Epoch 00012: val_acc did not improve from 0.76620\n",
      "lr: 0.0480, rho: 0.9100, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 1.7142 - acc: 0.7764 - rloss: 1.0780 - val_loss: 1.7684 - val_acc: 0.7661 - val_rloss: 1.0793\n",
      "Epoch 13/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6874 - acc: 0.7863 - rloss: 1.0789\n",
      "Epoch 00013: val_acc did not improve from 0.76620\n",
      "lr: 0.0520, rho: 0.9025, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 1.6877 - acc: 0.7862 - rloss: 1.0789 - val_loss: 1.8322 - val_acc: 0.7518 - val_rloss: 1.0776\n",
      "Epoch 14/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6732 - acc: 0.7900 - rloss: 1.0791\n",
      "Epoch 00014: val_acc did not improve from 0.76620\n",
      "lr: 0.0560, rho: 0.8950, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 1.6730 - acc: 0.7899 - rloss: 1.0791 - val_loss: 1.7782 - val_acc: 0.7656 - val_rloss: 1.0774\n",
      "Epoch 15/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6522 - acc: 0.7979 - rloss: 1.0747\n",
      "Epoch 00015: val_acc improved from 0.76620 to 0.76820, saving model to model.015-0.7682.hdf5\n",
      "lr: 0.0600, rho: 0.8875, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 166ms/step - loss: 1.6525 - acc: 0.7977 - rloss: 1.0746 - val_loss: 1.7795 - val_acc: 0.7682 - val_rloss: 1.0728\n",
      "Epoch 16/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6269 - acc: 0.8052 - rloss: 1.0686\n",
      "Epoch 00016: val_acc improved from 0.76820 to 0.77810, saving model to model.016-0.7781.hdf5\n",
      "lr: 0.0640, rho: 0.8800, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 1.6274 - acc: 0.8051 - rloss: 1.0686 - val_loss: 1.7375 - val_acc: 0.7781 - val_rloss: 1.0630\n",
      "Epoch 17/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6041 - acc: 0.8092 - rloss: 1.0590\n",
      "Epoch 00017: val_acc improved from 0.77810 to 0.78450, saving model to model.017-0.7845.hdf5\n",
      "lr: 0.0680, rho: 0.8725, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 1.6043 - acc: 0.8090 - rloss: 1.0590 - val_loss: 1.7002 - val_acc: 0.7845 - val_rloss: 1.0557\n",
      "Epoch 18/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.5903 - acc: 0.8112 - rloss: 1.0535\n",
      "Epoch 00018: val_acc did not improve from 0.78450\n",
      "lr: 0.0720, rho: 0.8651, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 1.5900 - acc: 0.8113 - rloss: 1.0535 - val_loss: 1.7170 - val_acc: 0.7760 - val_rloss: 1.0503\n",
      "Epoch 19/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.5678 - acc: 0.8178 - rloss: 1.0461\n",
      "Epoch 00019: val_acc did not improve from 0.78450\n",
      "lr: 0.0760, rho: 0.8576, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 176ms/step - loss: 1.5676 - acc: 0.8179 - rloss: 1.0461 - val_loss: 1.7307 - val_acc: 0.7800 - val_rloss: 1.0434\n",
      "Epoch 20/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.5449 - acc: 0.8233 - rloss: 1.0381\n",
      "Epoch 00020: val_acc improved from 0.78450 to 0.79880, saving model to model.020-0.7988.hdf5\n",
      "lr: 0.0800, rho: 0.8501, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 1.5450 - acc: 0.8233 - rloss: 1.0380 - val_loss: 1.6336 - val_acc: 0.7988 - val_rloss: 1.0320\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/98 [============================>.] - ETA: 0s - loss: 1.5167 - acc: 0.8286 - rloss: 1.0262\n",
      "Epoch 00021: val_acc did not improve from 0.79880\n",
      "lr: 0.0790, rho: 0.8519, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 1.5171 - acc: 0.8286 - rloss: 1.0262 - val_loss: 1.6663 - val_acc: 0.7887 - val_rloss: 1.0206\n",
      "Epoch 22/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.4869 - acc: 0.8330 - rloss: 1.0131\n",
      "Epoch 00022: val_acc improved from 0.79880 to 0.80020, saving model to model.022-0.8002.hdf5\n",
      "lr: 0.0780, rho: 0.8537, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 1.4875 - acc: 0.8328 - rloss: 1.0130 - val_loss: 1.6011 - val_acc: 0.8002 - val_rloss: 1.0048\n",
      "Epoch 23/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.4544 - acc: 0.8404 - rloss: 0.9955\n",
      "Epoch 00023: val_acc improved from 0.80020 to 0.80320, saving model to model.023-0.8032.hdf5\n",
      "lr: 0.0770, rho: 0.8556, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 1.4547 - acc: 0.8401 - rloss: 0.9954 - val_loss: 1.5936 - val_acc: 0.8032 - val_rloss: 0.9860\n",
      "Epoch 24/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.4134 - acc: 0.8473 - rloss: 0.9754\n",
      "Epoch 00024: val_acc improved from 0.80320 to 0.80730, saving model to model.024-0.8073.hdf5\n",
      "lr: 0.0760, rho: 0.8575, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 1.4132 - acc: 0.8474 - rloss: 0.9753 - val_loss: 1.5363 - val_acc: 0.8073 - val_rloss: 0.9659\n",
      "Epoch 25/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.3749 - acc: 0.8519 - rloss: 0.9545\n",
      "Epoch 00025: val_acc improved from 0.80730 to 0.81260, saving model to model.025-0.8126.hdf5\n",
      "lr: 0.0750, rho: 0.8593, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 175ms/step - loss: 1.3754 - acc: 0.8517 - rloss: 0.9544 - val_loss: 1.5047 - val_acc: 0.8126 - val_rloss: 0.9429\n",
      "Epoch 26/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.3370 - acc: 0.8591 - rloss: 0.9322\n",
      "Epoch 00026: val_acc did not improve from 0.81260\n",
      "lr: 0.0740, rho: 0.8612, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 1.3381 - acc: 0.8587 - rloss: 0.9320 - val_loss: 1.5133 - val_acc: 0.8079 - val_rloss: 0.9204\n",
      "Epoch 27/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.3044 - acc: 0.8620 - rloss: 0.9083\n",
      "Epoch 00027: val_acc improved from 0.81260 to 0.81340, saving model to model.027-0.8134.hdf5\n",
      "lr: 0.0730, rho: 0.8631, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 1.3046 - acc: 0.8619 - rloss: 0.9082 - val_loss: 1.4443 - val_acc: 0.8134 - val_rloss: 0.8968\n",
      "Epoch 28/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.2738 - acc: 0.8636 - rloss: 0.8870\n",
      "Epoch 00028: val_acc improved from 0.81340 to 0.82590, saving model to model.028-0.8259.hdf5\n",
      "lr: 0.0720, rho: 0.8650, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 1.2740 - acc: 0.8635 - rloss: 0.8869 - val_loss: 1.4131 - val_acc: 0.8259 - val_rloss: 0.8779\n",
      "Epoch 29/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.2371 - acc: 0.8716 - rloss: 0.8679\n",
      "Epoch 00029: val_acc did not improve from 0.82590\n",
      "lr: 0.0710, rho: 0.8668, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 1.2374 - acc: 0.8715 - rloss: 0.8678 - val_loss: 1.4003 - val_acc: 0.8210 - val_rloss: 0.8573\n",
      "Epoch 30/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.2087 - acc: 0.8725 - rloss: 0.8458\n",
      "Epoch 00030: val_acc did not improve from 0.82590\n",
      "lr: 0.0700, rho: 0.8687, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 166ms/step - loss: 1.2090 - acc: 0.8724 - rloss: 0.8457 - val_loss: 1.3897 - val_acc: 0.8174 - val_rloss: 0.8347\n",
      "Epoch 31/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1756 - acc: 0.8758 - rloss: 0.8254\n",
      "Epoch 00031: val_acc improved from 0.82590 to 0.82860, saving model to model.031-0.8286.hdf5\n",
      "lr: 0.0690, rho: 0.8706, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 1.1756 - acc: 0.8757 - rloss: 0.8253 - val_loss: 1.3358 - val_acc: 0.8286 - val_rloss: 0.8154\n",
      "Epoch 32/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1520 - acc: 0.8770 - rloss: 0.8061\n",
      "Epoch 00032: val_acc improved from 0.82860 to 0.83110, saving model to model.032-0.8311.hdf5\n",
      "lr: 0.0680, rho: 0.8725, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 165ms/step - loss: 1.1520 - acc: 0.8770 - rloss: 0.8060 - val_loss: 1.3038 - val_acc: 0.8311 - val_rloss: 0.7965\n",
      "Epoch 33/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1208 - acc: 0.8832 - rloss: 0.7877\n",
      "Epoch 00033: val_acc did not improve from 0.83110\n",
      "lr: 0.0670, rho: 0.8743, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 178ms/step - loss: 1.1208 - acc: 0.8832 - rloss: 0.7876 - val_loss: 1.3503 - val_acc: 0.8173 - val_rloss: 0.7771\n",
      "Epoch 34/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0898 - acc: 0.8878 - rloss: 0.7687\n",
      "Epoch 00034: val_acc did not improve from 0.83110\n",
      "lr: 0.0660, rho: 0.8762, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 1.0913 - acc: 0.8873 - rloss: 0.7686 - val_loss: 1.3084 - val_acc: 0.8225 - val_rloss: 0.7598\n",
      "Epoch 35/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0709 - acc: 0.8868 - rloss: 0.7523\n",
      "Epoch 00035: val_acc improved from 0.83110 to 0.83430, saving model to model.035-0.8343.hdf5\n",
      "lr: 0.0650, rho: 0.8781, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 1.0706 - acc: 0.8870 - rloss: 0.7522 - val_loss: 1.2394 - val_acc: 0.8343 - val_rloss: 0.7439\n",
      "Epoch 36/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0373 - acc: 0.8937 - rloss: 0.7361\n",
      "Epoch 00036: val_acc did not improve from 0.83430\n",
      "lr: 0.0640, rho: 0.8799, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 1.0373 - acc: 0.8936 - rloss: 0.7361 - val_loss: 1.2693 - val_acc: 0.8266 - val_rloss: 0.7284\n",
      "Epoch 37/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0147 - acc: 0.8958 - rloss: 0.7206\n",
      "Epoch 00037: val_acc did not improve from 0.83430\n",
      "lr: 0.0630, rho: 0.8818, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 1.0150 - acc: 0.8955 - rloss: 0.7205 - val_loss: 1.2508 - val_acc: 0.8327 - val_rloss: 0.7124\n",
      "Epoch 38/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.9950 - acc: 0.8971 - rloss: 0.7059\n",
      "Epoch 00038: val_acc did not improve from 0.83430\n",
      "lr: 0.0620, rho: 0.8837, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.9950 - acc: 0.8970 - rloss: 0.7058 - val_loss: 1.2273 - val_acc: 0.8293 - val_rloss: 0.6986\n",
      "Epoch 39/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.9723 - acc: 0.9007 - rloss: 0.6913\n",
      "Epoch 00039: val_acc did not improve from 0.83430\n",
      "lr: 0.0610, rho: 0.8856, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 0.9720 - acc: 0.9009 - rloss: 0.6913 - val_loss: 1.2127 - val_acc: 0.8309 - val_rloss: 0.6834\n",
      "Epoch 40/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.9485 - acc: 0.9042 - rloss: 0.6756\n",
      "Epoch 00040: val_acc improved from 0.83430 to 0.83740, saving model to model.040-0.8374.hdf5\n",
      "lr: 0.0600, rho: 0.8874, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.9487 - acc: 0.9040 - rloss: 0.6755 - val_loss: 1.1629 - val_acc: 0.8374 - val_rloss: 0.6695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.9290 - acc: 0.9052 - rloss: 0.6634\n",
      "Epoch 00041: val_acc improved from 0.83740 to 0.84120, saving model to model.041-0.8412.hdf5\n",
      "lr: 0.0590, rho: 0.8893, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 165ms/step - loss: 0.9291 - acc: 0.9053 - rloss: 0.6633 - val_loss: 1.1601 - val_acc: 0.8412 - val_rloss: 0.6571\n",
      "Epoch 42/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.9062 - acc: 0.9093 - rloss: 0.6513\n",
      "Epoch 00042: val_acc did not improve from 0.84120\n",
      "lr: 0.0580, rho: 0.8912, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 165ms/step - loss: 0.9062 - acc: 0.9093 - rloss: 0.6512 - val_loss: 1.1696 - val_acc: 0.8409 - val_rloss: 0.6449\n",
      "Epoch 43/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8957 - acc: 0.9084 - rloss: 0.6387\n",
      "Epoch 00043: val_acc did not improve from 0.84120\n",
      "lr: 0.0570, rho: 0.8931, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 173ms/step - loss: 0.8959 - acc: 0.9084 - rloss: 0.6386 - val_loss: 1.1585 - val_acc: 0.8363 - val_rloss: 0.6330\n",
      "Epoch 44/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8702 - acc: 0.9139 - rloss: 0.6274\n",
      "Epoch 00044: val_acc improved from 0.84120 to 0.84470, saving model to model.044-0.8447.hdf5\n",
      "lr: 0.0560, rho: 0.8949, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.8704 - acc: 0.9138 - rloss: 0.6274 - val_loss: 1.1133 - val_acc: 0.8447 - val_rloss: 0.6220\n",
      "Epoch 45/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8570 - acc: 0.9155 - rloss: 0.6167\n",
      "Epoch 00045: val_acc improved from 0.84470 to 0.84530, saving model to model.045-0.8453.hdf5\n",
      "lr: 0.0550, rho: 0.8968, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 0.8574 - acc: 0.9154 - rloss: 0.6166 - val_loss: 1.0977 - val_acc: 0.8453 - val_rloss: 0.6110\n",
      "Epoch 46/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8378 - acc: 0.9182 - rloss: 0.6057\n",
      "Epoch 00046: val_acc did not improve from 0.84530\n",
      "lr: 0.0540, rho: 0.8987, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.8380 - acc: 0.9180 - rloss: 0.6057 - val_loss: 1.1129 - val_acc: 0.8350 - val_rloss: 0.6000\n",
      "Epoch 47/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8238 - acc: 0.9199 - rloss: 0.5952\n",
      "Epoch 00047: val_acc did not improve from 0.84530\n",
      "lr: 0.0530, rho: 0.9005, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 0.8240 - acc: 0.9198 - rloss: 0.5951 - val_loss: 1.1163 - val_acc: 0.8368 - val_rloss: 0.5907\n",
      "Epoch 48/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8086 - acc: 0.9199 - rloss: 0.5858\n",
      "Epoch 00048: val_acc did not improve from 0.84530\n",
      "lr: 0.0520, rho: 0.9024, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.8085 - acc: 0.9199 - rloss: 0.5858 - val_loss: 1.1033 - val_acc: 0.8433 - val_rloss: 0.5808\n",
      "Epoch 49/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7991 - acc: 0.9209 - rloss: 0.5767\n",
      "Epoch 00049: val_acc improved from 0.84530 to 0.84630, saving model to model.049-0.8463.hdf5\n",
      "lr: 0.0510, rho: 0.9043, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.7991 - acc: 0.9208 - rloss: 0.5766 - val_loss: 1.0924 - val_acc: 0.8463 - val_rloss: 0.5727\n",
      "Epoch 50/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7797 - acc: 0.9249 - rloss: 0.5686\n",
      "Epoch 00050: val_acc did not improve from 0.84630\n",
      "lr: 0.0500, rho: 0.9062, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 163ms/step - loss: 0.7797 - acc: 0.9249 - rloss: 0.5686 - val_loss: 1.1110 - val_acc: 0.8397 - val_rloss: 0.5642\n",
      "Epoch 51/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7600 - acc: 0.9290 - rloss: 0.5595\n",
      "Epoch 00051: val_acc did not improve from 0.84630\n",
      "lr: 0.0490, rho: 0.9080, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 0.7601 - acc: 0.9290 - rloss: 0.5595 - val_loss: 1.0746 - val_acc: 0.8454 - val_rloss: 0.5553\n",
      "Epoch 52/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7527 - acc: 0.9288 - rloss: 0.5517\n",
      "Epoch 00052: val_acc did not improve from 0.84630\n",
      "lr: 0.0481, rho: 0.9099, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 16s 166ms/step - loss: 0.7524 - acc: 0.9289 - rloss: 0.5517 - val_loss: 1.0803 - val_acc: 0.8430 - val_rloss: 0.5478\n",
      "Epoch 53/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7397 - acc: 0.9309 - rloss: 0.5435\n",
      "Epoch 00053: val_acc improved from 0.84630 to 0.84900, saving model to model.053-0.8490.hdf5\n",
      "lr: 0.0471, rho: 0.9118, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.7400 - acc: 0.9309 - rloss: 0.5435 - val_loss: 1.0390 - val_acc: 0.8490 - val_rloss: 0.5392\n",
      "Epoch 54/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7262 - acc: 0.9322 - rloss: 0.5349\n",
      "Epoch 00054: val_acc did not improve from 0.84900\n",
      "lr: 0.0461, rho: 0.9137, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 168ms/step - loss: 0.7265 - acc: 0.9322 - rloss: 0.5349 - val_loss: 1.0424 - val_acc: 0.8475 - val_rloss: 0.5303\n",
      "Epoch 55/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7070 - acc: 0.9359 - rloss: 0.5264\n",
      "Epoch 00055: val_acc did not improve from 0.84900\n",
      "lr: 0.0451, rho: 0.9155, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 0.7074 - acc: 0.9359 - rloss: 0.5263 - val_loss: 1.0521 - val_acc: 0.8405 - val_rloss: 0.5228\n",
      "Epoch 56/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7006 - acc: 0.9365 - rloss: 0.5198\n",
      "Epoch 00056: val_acc improved from 0.84900 to 0.85450, saving model to model.056-0.8545.hdf5\n",
      "lr: 0.0441, rho: 0.9174, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.7007 - acc: 0.9364 - rloss: 0.5198 - val_loss: 1.0136 - val_acc: 0.8545 - val_rloss: 0.5165\n",
      "Epoch 57/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6843 - acc: 0.9388 - rloss: 0.5132\n",
      "Epoch 00057: val_acc improved from 0.85450 to 0.85510, saving model to model.057-0.8551.hdf5\n",
      "lr: 0.0431, rho: 0.9193, wt_decay: 1.0000e-04\n",
      "Reducing weight decay by half...\n",
      "98/98 [==============================] - 17s 177ms/step - loss: 0.6845 - acc: 0.9389 - rloss: 0.5132 - val_loss: 1.0050 - val_acc: 0.8551 - val_rloss: 0.5097\n",
      "Epoch 58/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6755 - acc: 0.9397 - rloss: 0.5060\n",
      "Epoch 00058: val_acc did not improve from 0.85510\n",
      "lr: 0.0421, rho: 0.9211, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 0.6756 - acc: 0.9397 - rloss: 0.5059 - val_loss: 1.0354 - val_acc: 0.8455 - val_rloss: 0.5025\n",
      "Epoch 59/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6606 - acc: 0.9420 - rloss: 0.4988\n",
      "Epoch 00059: val_acc did not improve from 0.85510\n",
      "lr: 0.0411, rho: 0.9230, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 0.6605 - acc: 0.9419 - rloss: 0.4987 - val_loss: 1.0373 - val_acc: 0.8438 - val_rloss: 0.4953\n",
      "Epoch 60/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6504 - acc: 0.9443 - rloss: 0.4920\n",
      "Epoch 00060: val_acc did not improve from 0.85510\n",
      "lr: 0.0401, rho: 0.9249, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 166ms/step - loss: 0.6505 - acc: 0.9442 - rloss: 0.4920 - val_loss: 1.0139 - val_acc: 0.8484 - val_rloss: 0.4888\n",
      "Epoch 61/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6411 - acc: 0.9450 - rloss: 0.4856\n",
      "Epoch 00061: val_acc did not improve from 0.85510\n",
      "lr: 0.0391, rho: 0.9268, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 173ms/step - loss: 0.6415 - acc: 0.9449 - rloss: 0.4855 - val_loss: 1.0160 - val_acc: 0.8490 - val_rloss: 0.4824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6313 - acc: 0.9467 - rloss: 0.4797\n",
      "Epoch 00062: val_acc did not improve from 0.85510\n",
      "lr: 0.0381, rho: 0.9286, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 174ms/step - loss: 0.6311 - acc: 0.9468 - rloss: 0.4796 - val_loss: 0.9925 - val_acc: 0.8534 - val_rloss: 0.4762\n",
      "Epoch 63/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6203 - acc: 0.9470 - rloss: 0.4734\n",
      "Epoch 00063: val_acc did not improve from 0.85510\n",
      "lr: 0.0371, rho: 0.9305, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 175ms/step - loss: 0.6200 - acc: 0.9472 - rloss: 0.4734 - val_loss: 0.9991 - val_acc: 0.8517 - val_rloss: 0.4706\n",
      "Epoch 64/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.9501 - rloss: 0.4679\n",
      "Epoch 00064: val_acc did not improve from 0.85510\n",
      "lr: 0.0361, rho: 0.9324, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 0.6116 - acc: 0.9501 - rloss: 0.4679 - val_loss: 0.9916 - val_acc: 0.8501 - val_rloss: 0.4652\n",
      "Epoch 65/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.9515 - rloss: 0.4626\n",
      "Epoch 00065: val_acc did not improve from 0.85510\n",
      "lr: 0.0351, rho: 0.9343, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 0.6002 - acc: 0.9516 - rloss: 0.4626 - val_loss: 0.9848 - val_acc: 0.8541 - val_rloss: 0.4597\n",
      "Epoch 66/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5865 - acc: 0.9541 - rloss: 0.4570\n",
      "Epoch 00066: val_acc improved from 0.85510 to 0.85720, saving model to model.066-0.8572.hdf5\n",
      "lr: 0.0341, rho: 0.9361, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 0.5867 - acc: 0.9540 - rloss: 0.4570 - val_loss: 0.9656 - val_acc: 0.8572 - val_rloss: 0.4541\n",
      "Epoch 67/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5838 - acc: 0.9536 - rloss: 0.4516\n",
      "Epoch 00067: val_acc improved from 0.85720 to 0.85870, saving model to model.067-0.8587.hdf5\n",
      "lr: 0.0331, rho: 0.9380, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 0.5836 - acc: 0.9536 - rloss: 0.4516 - val_loss: 0.9443 - val_acc: 0.8587 - val_rloss: 0.4489\n",
      "Epoch 68/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5664 - acc: 0.9579 - rloss: 0.4466\n",
      "Epoch 00068: val_acc did not improve from 0.85870\n",
      "lr: 0.0321, rho: 0.9399, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 166ms/step - loss: 0.5665 - acc: 0.9579 - rloss: 0.4466 - val_loss: 0.9678 - val_acc: 0.8572 - val_rloss: 0.4442\n",
      "Epoch 69/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5608 - acc: 0.9587 - rloss: 0.4418\n",
      "Epoch 00069: val_acc improved from 0.85870 to 0.85950, saving model to model.069-0.8595.hdf5\n",
      "lr: 0.0311, rho: 0.9417, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 175ms/step - loss: 0.5608 - acc: 0.9588 - rloss: 0.4418 - val_loss: 0.9679 - val_acc: 0.8595 - val_rloss: 0.4396\n",
      "Epoch 70/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5570 - acc: 0.9582 - rloss: 0.4373\n",
      "Epoch 00070: val_acc did not improve from 0.85950\n",
      "lr: 0.0301, rho: 0.9436, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 0.5570 - acc: 0.9581 - rloss: 0.4372 - val_loss: 0.9580 - val_acc: 0.8585 - val_rloss: 0.4344\n",
      "Epoch 71/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5461 - acc: 0.9596 - rloss: 0.4318\n",
      "Epoch 00071: val_acc did not improve from 0.85950\n",
      "lr: 0.0291, rho: 0.9455, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.5460 - acc: 0.9597 - rloss: 0.4317 - val_loss: 0.9783 - val_acc: 0.8552 - val_rloss: 0.4294\n",
      "Epoch 72/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5341 - acc: 0.9631 - rloss: 0.4271\n",
      "Epoch 00072: val_acc did not improve from 0.85950\n",
      "lr: 0.0281, rho: 0.9474, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 174ms/step - loss: 0.5343 - acc: 0.9630 - rloss: 0.4271 - val_loss: 0.9730 - val_acc: 0.8550 - val_rloss: 0.4246\n",
      "Epoch 73/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5256 - acc: 0.9637 - rloss: 0.4224\n",
      "Epoch 00073: val_acc did not improve from 0.85950\n",
      "lr: 0.0271, rho: 0.9492, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.5253 - acc: 0.9638 - rloss: 0.4224 - val_loss: 0.9699 - val_acc: 0.8510 - val_rloss: 0.4203\n",
      "Epoch 74/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5195 - acc: 0.9651 - rloss: 0.4185\n",
      "Epoch 00074: val_acc did not improve from 0.85950\n",
      "lr: 0.0261, rho: 0.9511, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 167ms/step - loss: 0.5191 - acc: 0.9653 - rloss: 0.4185 - val_loss: 0.9360 - val_acc: 0.8578 - val_rloss: 0.4165\n",
      "Epoch 75/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5117 - acc: 0.9665 - rloss: 0.4147\n",
      "Epoch 00075: val_acc did not improve from 0.85950\n",
      "lr: 0.0251, rho: 0.9530, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 173ms/step - loss: 0.5116 - acc: 0.9666 - rloss: 0.4147 - val_loss: 0.9537 - val_acc: 0.8553 - val_rloss: 0.4129\n",
      "Epoch 76/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5041 - acc: 0.9679 - rloss: 0.4110\n",
      "Epoch 00076: val_acc improved from 0.85950 to 0.86290, saving model to model.076-0.8629.hdf5\n",
      "lr: 0.0241, rho: 0.9548, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 176ms/step - loss: 0.5040 - acc: 0.9679 - rloss: 0.4110 - val_loss: 0.9363 - val_acc: 0.8629 - val_rloss: 0.4090\n",
      "Epoch 77/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4973 - acc: 0.9682 - rloss: 0.4070\n",
      "Epoch 00077: val_acc improved from 0.86290 to 0.86430, saving model to model.077-0.8643.hdf5\n",
      "lr: 0.0231, rho: 0.9567, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.4971 - acc: 0.9683 - rloss: 0.4070 - val_loss: 0.9197 - val_acc: 0.8643 - val_rloss: 0.4051\n",
      "Epoch 78/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4892 - acc: 0.9702 - rloss: 0.4033\n",
      "Epoch 00078: val_acc did not improve from 0.86430\n",
      "lr: 0.0221, rho: 0.9586, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 0.4893 - acc: 0.9702 - rloss: 0.4033 - val_loss: 0.9464 - val_acc: 0.8603 - val_rloss: 0.4015\n",
      "Epoch 79/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4813 - acc: 0.9720 - rloss: 0.3997\n",
      "Epoch 00079: val_acc improved from 0.86430 to 0.86950, saving model to model.079-0.8695.hdf5\n",
      "lr: 0.0211, rho: 0.9605, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.4818 - acc: 0.9718 - rloss: 0.3997 - val_loss: 0.9152 - val_acc: 0.8695 - val_rloss: 0.3980\n",
      "Epoch 80/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.9719 - rloss: 0.3965\n",
      "Epoch 00080: val_acc did not improve from 0.86950\n",
      "lr: 0.0201, rho: 0.9623, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 177ms/step - loss: 0.4772 - acc: 0.9719 - rloss: 0.3965 - val_loss: 0.9332 - val_acc: 0.8630 - val_rloss: 0.3948\n",
      "Epoch 81/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.9758 - rloss: 0.3933\n",
      "Epoch 00081: val_acc did not improve from 0.86950\n",
      "lr: 0.0191, rho: 0.9642, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 0.4652 - acc: 0.9756 - rloss: 0.3933 - val_loss: 0.9468 - val_acc: 0.8596 - val_rloss: 0.3916\n",
      "Epoch 82/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.9761 - rloss: 0.3901\n",
      "Epoch 00082: val_acc did not improve from 0.86950\n",
      "lr: 0.0181, rho: 0.9661, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 166ms/step - loss: 0.4605 - acc: 0.9759 - rloss: 0.3901 - val_loss: 0.9170 - val_acc: 0.8651 - val_rloss: 0.3886\n",
      "Epoch 83/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.9766 - rloss: 0.3873\n",
      "Epoch 00083: val_acc did not improve from 0.86950\n",
      "lr: 0.0171, rho: 0.9680, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 165ms/step - loss: 0.4567 - acc: 0.9767 - rloss: 0.3873 - val_loss: 0.9095 - val_acc: 0.8678 - val_rloss: 0.3859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.9780 - rloss: 0.3844\n",
      "Epoch 00084: val_acc did not improve from 0.86950\n",
      "lr: 0.0161, rho: 0.9698, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 0.4490 - acc: 0.9781 - rloss: 0.3844 - val_loss: 0.9266 - val_acc: 0.8672 - val_rloss: 0.3830\n",
      "Epoch 85/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.9785 - rloss: 0.3817\n",
      "Epoch 00085: val_acc did not improve from 0.86950\n",
      "lr: 0.0151, rho: 0.9717, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.4464 - acc: 0.9784 - rloss: 0.3817 - val_loss: 0.9209 - val_acc: 0.8668 - val_rloss: 0.3804\n",
      "Epoch 86/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.9787 - rloss: 0.3792\n",
      "Epoch 00086: val_acc did not improve from 0.86950\n",
      "lr: 0.0141, rho: 0.9736, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 0.4408 - acc: 0.9788 - rloss: 0.3791 - val_loss: 0.9026 - val_acc: 0.8686 - val_rloss: 0.3780\n",
      "Epoch 87/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4305 - acc: 0.9822 - rloss: 0.3768\n",
      "Epoch 00087: val_acc improved from 0.86950 to 0.87200, saving model to model.087-0.8720.hdf5\n",
      "lr: 0.0131, rho: 0.9754, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.4310 - acc: 0.9820 - rloss: 0.3768 - val_loss: 0.8956 - val_acc: 0.8720 - val_rloss: 0.3756\n",
      "Epoch 88/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4276 - acc: 0.9818 - rloss: 0.3744\n",
      "Epoch 00088: val_acc did not improve from 0.87200\n",
      "lr: 0.0121, rho: 0.9773, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 165ms/step - loss: 0.4276 - acc: 0.9818 - rloss: 0.3744 - val_loss: 0.9183 - val_acc: 0.8705 - val_rloss: 0.3732\n",
      "Epoch 89/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4247 - acc: 0.9821 - rloss: 0.3721\n",
      "Epoch 00089: val_acc improved from 0.87200 to 0.87250, saving model to model.089-0.8725.hdf5\n",
      "lr: 0.0111, rho: 0.9792, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.4248 - acc: 0.9820 - rloss: 0.3721 - val_loss: 0.8967 - val_acc: 0.8725 - val_rloss: 0.3709\n",
      "Epoch 90/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.9834 - rloss: 0.3700\n",
      "Epoch 00090: val_acc improved from 0.87250 to 0.87370, saving model to model.090-0.8737.hdf5\n",
      "lr: 0.0101, rho: 0.9811, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 0.4193 - acc: 0.9835 - rloss: 0.3700 - val_loss: 0.8861 - val_acc: 0.8737 - val_rloss: 0.3691\n",
      "Epoch 91/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4143 - acc: 0.9852 - rloss: 0.3683\n",
      "Epoch 00091: val_acc did not improve from 0.87370\n",
      "lr: 0.0091, rho: 0.9829, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 174ms/step - loss: 0.4142 - acc: 0.9851 - rloss: 0.3682 - val_loss: 0.8909 - val_acc: 0.8734 - val_rloss: 0.3673\n",
      "Epoch 92/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.9843 - rloss: 0.3665\n",
      "Epoch 00092: val_acc improved from 0.87370 to 0.87520, saving model to model.092-0.8752.hdf5\n",
      "lr: 0.0081, rho: 0.9848, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 170ms/step - loss: 0.4127 - acc: 0.9843 - rloss: 0.3665 - val_loss: 0.8835 - val_acc: 0.8752 - val_rloss: 0.3657\n",
      "Epoch 93/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4086 - acc: 0.9853 - rloss: 0.3651\n",
      "Epoch 00093: val_acc did not improve from 0.87520\n",
      "lr: 0.0071, rho: 0.9867, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 165ms/step - loss: 0.4085 - acc: 0.9854 - rloss: 0.3651 - val_loss: 0.8947 - val_acc: 0.8715 - val_rloss: 0.3643\n",
      "Epoch 94/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4037 - acc: 0.9867 - rloss: 0.3637\n",
      "Epoch 00094: val_acc did not improve from 0.87520\n",
      "lr: 0.0061, rho: 0.9886, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 0.4037 - acc: 0.9867 - rloss: 0.3637 - val_loss: 0.8820 - val_acc: 0.8747 - val_rloss: 0.3630\n",
      "Epoch 95/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4007 - acc: 0.9877 - rloss: 0.3625\n",
      "Epoch 00095: val_acc did not improve from 0.87520\n",
      "lr: 0.0051, rho: 0.9904, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 166ms/step - loss: 0.4007 - acc: 0.9877 - rloss: 0.3625 - val_loss: 0.8795 - val_acc: 0.8750 - val_rloss: 0.3620\n",
      "Epoch 96/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.9879 - rloss: 0.3616\n",
      "Epoch 00096: val_acc improved from 0.87520 to 0.87700, saving model to model.096-0.8770.hdf5\n",
      "lr: 0.0041, rho: 0.9923, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 172ms/step - loss: 0.3999 - acc: 0.9879 - rloss: 0.3616 - val_loss: 0.8750 - val_acc: 0.8770 - val_rloss: 0.3611\n",
      "Epoch 97/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3952 - acc: 0.9885 - rloss: 0.3607\n",
      "Epoch 00097: val_acc did not improve from 0.87700\n",
      "lr: 0.0031, rho: 0.9942, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 16s 168ms/step - loss: 0.3952 - acc: 0.9885 - rloss: 0.3607 - val_loss: 0.8787 - val_acc: 0.8770 - val_rloss: 0.3603\n",
      "Epoch 98/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3919 - acc: 0.9896 - rloss: 0.3600\n",
      "Epoch 00098: val_acc did not improve from 0.87700\n",
      "lr: 0.0021, rho: 0.9960, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 177ms/step - loss: 0.3920 - acc: 0.9896 - rloss: 0.3600 - val_loss: 0.8738 - val_acc: 0.8753 - val_rloss: 0.3597\n",
      "Epoch 99/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3926 - acc: 0.9892 - rloss: 0.3596\n",
      "Epoch 00099: val_acc improved from 0.87700 to 0.87720, saving model to model.099-0.8772.hdf5\n",
      "lr: 0.0011, rho: 0.9979, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 171ms/step - loss: 0.3927 - acc: 0.9891 - rloss: 0.3596 - val_loss: 0.8756 - val_acc: 0.8772 - val_rloss: 0.3594\n",
      "Epoch 100/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3931 - acc: 0.9892 - rloss: 0.3593\n",
      "Epoch 00100: val_acc improved from 0.87720 to 0.87730, saving model to model.100-0.8773.hdf5\n",
      "lr: 0.0001, rho: 0.9998, wt_decay: 1.0000e-04\n",
      "98/98 [==============================] - 17s 169ms/step - loss: 0.3932 - acc: 0.9891 - rloss: 0.3593 - val_loss: 0.8743 - val_acc: 0.8773 - val_rloss: 0.3592\n",
      "Model took 1673.54 seconds to train\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd5hV1bnH8e97Zs70XoBhYGCoFkRQQI3GXrB7bcFYE6O5MeaqiUlMbmI08Sam3pioscUaS7AkMV7sDbsCIh3pMAxlmMb0dtb9Y52RYRhggDlzpvw+z7OfmbP32nu/h/Fxn/estd5lzjlERERERESk9wtEOwARERERERHpGkrwRERERERE+ggleCIiIiIiIn2EEjwREREREZE+QgmeiIiIiIhIH6EET0REREREpI9Qgieyj8xsuJk5M4vtRNsrzOzd7ohLRESkt9KzVWTvKcGTfsXMVptZo5nltNs/N/wgGR6dyLaLJdnMqs1sRrRjERER2Z2e/Gzdk0RRpK9Qgif90SrgotYXZnYQkBi9cHZwPtAAnGxmed15Yz0ARURkL/X0Z6tIv6EET/qjx4DL2ry+HHi0bQMzSzezR82sxMzWmNlPzCwQPhZjZr8zsy1mthI4vYNz/2pmG8xsvZndZmYxexDf5cA9wDzg4nbXHmpmz4XjKjWzO9scu8rMFptZlZktMrNDwvudmY1q0+5hM7st/PuxZlZkZj80s43AQ2aWaWYvhO9RHv59SJvzs8zsITMrDh//Z3j/AjM7s027YPjfaMIevHcREemdevqzdQdmFm9mfww/z4rDv8eHj+WEn38VZlZmZu+0ifWH4RiqzGypmZ2wL3GIdDUleNIffQikmdn+4YfDV4C/tWvzZyAdGAEcg39ofS187CrgDGAiMAnf49bWI0AzMCrc5mTgG50JzMwKgGOBx8PbZW2OxQAvAGuA4UA+8FT42AXALeH2acBZQGln7gkMArKAYcDV+P8vPBR+XQDUAXe2af8YkAQcCAwA/je8/1HgkjbtTgM2OOfmdjIOERHpvXrss3UX/hs4HJgAHAxMAX4SPvY9oAjIBQYCPwacmY0FrgUmO+dSgVOA1fsYh0iXUoIn/VXrN40nAUuA9a0H2jyYfuScq3LOrQZ+D1wabnIh8Efn3DrnXBnwqzbnDgROBa53ztU45zbjE6BpnYzrMmCec24R8CRwoJlNDB+bAgwGvh++dr1zrnVS+TeA3zjnPnHecufcmk7eMwT8zDnX4Jyrc86VOueedc7VOueqgP/BP4gJDxk9FfhP51y5c67JOfd2+Dp/A04zs7Tw60vx/84iItI/9NRn685cDPzcObfZOVcC3NomniYgDxgWfta945xzQAsQDxxgZkHn3Grn3Ip9jEOkS2m+jfRXjwEzgULaDSEBcoA4fE9ZqzX4HjPwSda6dsdaDQOCwAYza90XaNd+Vy4D7gdwzhWb2dv4YS6fAkOBNc655g7OGwrs7QOmxDlX3/rCzJLwD86pQGZ4d2r44TwUKHPOlbe/SDje94DzzOwf+IfxdXsZk4iI9D499dm6M4M7iGdw+Pff4kfGvBK+533Oududc8vN7PrwsQPN7GXgu8654n2MRaTLqAdP+qVw79Yq/DDC59od3oL/5m5Ym30FbPsmcgM+0Wl7rNU6fIGUHOdcRnhLc84duLuYzOxLwGjgR2a2MTwn7jDgonDxk3VAwU4KoawDRu7k0rX4IZWtBrU77tq9/h4wFjjMOZcGHN0aYvg+WWaWsZN7PYIfpnkB8IFzbv1O2omISB/TE5+tu1HcQTzF4fdS5Zz7nnNuBHAm8N3WuXbOuSecc0eFz3XAr/cxDpEupQRP+rMrgeOdczVtdzrnWoDpwP+YWaqZDQO+y7a5BNOB/zKzIWaWCdzU5twNwCvA780szcwCZjbSzI7pRDyXA68CB+DnA0wAxuGTs1OBj/EPwNvNL6WQYGZHhs99ALjRzA41b1Q4boC5wFfDE9inEh5uuQup+Hl3FWaWBfys3ft7Ebg7XIwlaGZHtzn3n8Ah+J679t/eiohI39fTnq2t4sPPzdYtgJ8K8RMzyzW/xMPNrfGY2RnhZ6kBW/FDM1vMbKyZHR8uxlKPf1627OG/kUhEKcGTfss5t8I5N2snh78D1AArgXeBJ4AHw8fuB14GPgPmsOO3lJfhh6EsAsqBZ/Dj+HfKzBLw8w/+7Jzb2GZbhR/ycnn44XgmfoL5Wvzk76+E38vT+LlyTwBV+EQrK3z568LnVeDnG/xzV7EAf8SXtt6CnzT/Urvjl+K/hV0CbAaubz3gnKsDnsUPz2n/7yIiIn1cT3q2tlONT8Zat+OB24BZ+KrV88P3vS3cfjTwWvi8D4C7nXNv4eff3Y5/Rm7EFxv78R7EIRJx5ueLioh0DTO7GRjjnLtkt41FREREpEupyIqIdJnwkM4r2VaFTERERES6kYZoikiXMLOr8BPhX3TOzYx2PCIiIiL9kYZoioiIiIiI9BHqwRMREREREekjlOCJiIiIiIj0Eb2uyEpOTo4bPnx4tMMQEZFuMHv27C3Oudxox9Fb6BkpItI/7Or52OsSvOHDhzNr1s6WVxERkb7EzNZEO4beRM9IEZH+YVfPRw3RFBERERER6SOU4ImIiIiIiPQRSvBERERERET6iIjNwTOzB4EzgM3OuXEdHDfgDuA0oBa4wjk3Z2/u1dTURFFREfX19fsSco+XkJDAkCFDCAaD0Q5FRERERCRq9Pl/5yJZZOVh4E7g0Z0cPxUYHd4OA/4S/rnHioqKSE1NZfjw4fi8se9xzlFaWkpRURGFhYXRDkdEREREJGr0+X/nIjZE0zk3EyjbRZOzgUed9yGQYWZ5e3Ov+vp6srOz++wfF8DMyM7O7vPfUoiIiIiI7I4+/+9cNOfg5QPr2rwuCu/bK335j9uqP7xHEREREZHO6A+fjffmPUYzwesoWtdhQ7OrzWyWmc0qKSmJcFh7rqKigrvvvnuPzzvttNOoqKiIQEQiIiIiIhIpPfnzfzQTvCJgaJvXQ4Dijho65+5zzk1yzk3Kze1wwfao2tkfuKWlZZfnzZgxg4yMjEiFJSIiIiIiEdCTP/9HssjK7jwPXGtmT+GLq1Q65zZEMZ69dtNNN7FixQomTJhAMBgkJSWFvLw85s6dy6JFizjnnHNYt24d9fX1XHfddVx99dUADB8+nFmzZlFdXc2pp57KUUcdxfvvv09+fj7/+te/SExMjPI7ExHxQiFHdWMzZdWNlFQ3UFLVQHV9M/HBAInBGBLjYogJ+IEZhmEGh4/IjnLUsqdmzN9AWkKQo0bnRDsUEZEerSd//o/kMglPAscCOWZWBPwMCAI45+4BZuCXSFiOXybha5GKJdJuv/12FixYwNy5c3nrrbc4/fTTWbBgwRfVbh588EGysrKoq6tj8uTJnHfeeWRnb//BZ9myZTz55JPcf//9XHjhhTz77LNccskl0Xg7ItIHOOc6HLfvnGNrXTMbttZRXFHH+op6NlbWsaWqkS3VDWypbqC+KURTKERLyNHQFKKmoZnqxmZch4PoOxYTMFb88rQufEfSHf731c8ZNSBFCZ6IyG705M//EUvwnHMX7ea4A77d1fe99d8LWVS8tUuvecDgNH525oGdbj9lypTtSpn+6U9/4h//+AcA69atY9myZTv8gQsLC5kwYQIAhx56KKtXr973wEWk12tuCdEccgRjAgTMT7Z2zhFy0BwKsXlrA2vLallbVsua0lpWbalm1ZYaVpfWYkBGUpCMxDjiYgOUVjewpbqRxpbQdveICRjZyXHkpMSTnRLHoPQYYmMCBANGMCZAakKQlIRYUuNjyUqOIzc1ngFp8aTEx1LfFKK+qYXaxhZCzu1REig9T0pCLNUNzdEOQ0Rkj+jz//aiOUSzz0pOTv7i97feeovXXnuNDz74gKSkJI499tgOS53Gx8d/8XtMTAx1dXXdEquI9CyhkGPD1nreXlrCm0s3897yLdQ2bhvPHzAI7SSJCsYYw7KTKcxJ5tixAzCgvLaRitomGppDjB6YQm5qPLkp8QxKT2BwRiL5GYnkpMR/MbxS+reU+Fiq6pXgiYjsqZ70+b/PJXh7kml3ldTUVKqqqjo8VllZSWZmJklJSSxZsoQPP/ywm6MTke7S3BKipqGFxpYQjS2+Z6uyronKuia21jWxobKedWW1rCuvY/PWeuqbWmhoDtHYHKKhOURDcwtNLduyt/yMRM49JJ+89ERaQo7mkCMUcgQCRmzAiAkYOSlxDM1KoiAribz0RCVqsk9SE2LZUKn1VkWkd9Hn/+31uQQvGrKzsznyyCMZN24ciYmJDBw48ItjU6dO5Z577mH8+PGMHTuWww8/PIqRikhXq29qYebnJby4YCOvLdpE1W6Gt2UkBRmamcSQzCSS4mKIjw0QFxsgPjaG+GCA+NgAGYm+yMXI3JR+scaP9Bwp8bFUqwdPRGS3evLnfyV4XeSJJ57ocH98fDwvvvhih8dax9nm5OSwYMGCL/bfeOONXR6fiOy56oZmlm2qYtnm8Ly28Ny26oYmQiFfsKS8tom6phYykoJMHTeI/fLSiIuxL5K29MQgaYlB0hODDEyLJzUhGO23JbJTKfFBzcETEemknvr5XwmeiPQrrVUkiyt9Fcmi8jrWV9Sxqc2QyfqmForK/bFWsQGjICuJ4TnJZCSmYmYEDJLjYzl+vwEcMTKbYEw0lxYV2XetRVZahwKLiEjvowRPRPoM5xwbKuspq2lka3ju24bKetaU1rAmXGlyQ0U9dU3bL0IaFxtgUFrCdkMmJxZkctGUAsYMTGX0gBSGZCYSqwRO+rjUeP+xoKaxWb3NIiK9lBI8EenV6pta+GhVGW8s3sRrizezvmLHClSp8bEUZCcxdmAqx40dQF56AnnpiQzOSCA/M5Gc5Hj1Vojge/DAD09Wgici0jspwRORHsU5x9x1Fby+eDNbqhsor22kvLYJHKQlxpKaECQYY6yvqGP1llqKK+twDhKCAY4alcs3jxnBgNQE0tvMe8tKjlOxEpFOSAn34FXXN0N6lIMREZG9ogRPRLqdc471FXUs21RNbIyREPRDIz9eVcb0Wev4fFM1MQEjKzmOrKQ4MpKCWACKK+rZWl9FQ3OI/IxEJg/PZFj2EA4ems6XRuaQEIyJ9lsT6dVae/B2Vw1WRER6LiV4IhJRJVUNrC6tYW1pLWvKallUvJW56yrYUt3QYfuJBRn86tyDOGN8noaIiXSz1LY9eCIi0ispwYuClJQUqqurox2GSJepbWympqGFhuYW6ptCLNm4lfeWl/L+ii2sKa39op0ZFGYnc/ToHCYWZLB/XhoAdU0t1DW2MCI3mVEDUqP1NkT6vbZz8EREpOt05+d/JXgislvlNY0s3VRFRW0TW+ub2FrXRFF5Hcs2V/H5pmpKqnbsjUuJj+XwEVlcevgwRg1IoSArifzMROJjNYxSpKdKUQ+eiEivpwSvC/zwhz9k2LBhXHPNNQDccsstmBkzZ86kvLycpqYmbrvtNs4+++woRyqyexW1jSws3sr89ZXMX1/JvKIK1pXtWJkyKS6G0QNSOGZMLoU5yaQmxJIQG0N8MMDQrCTG56drWQGRXiY13g+L1hw8EZFd68mf/5XgdYFp06Zx/fXXf/EHnj59Oi+99BI33HADaWlpbNmyhcMPP5yzzjpLlfykR9ha38Rn6yqYs6aCNWU1lNf4SpUlVQ3bLTOQn5HIwUPT+eqUYRw4OI2clHjSEmNJSwySGh+r/55F+pjkeN/Drh48EZFd68mf//tegvfiTbBxftdec9BBcOrtOz08ceJENm/eTHFxMSUlJWRmZpKXl8cNN9zAzJkzCQQCrF+/nk2bNjFo0KCujU1kJ5xzLCzeyksLNrJ8czW1TS3UNjRTVtvIqi01OOfnxA1OTyQzOUhmUhzDspO4eFABB+WnM25wOpnJcdF+GyLSjWJjAiQGY6huaIp2KCIinafP/9vpewlelJx//vk888wzbNy4kWnTpvH4449TUlLC7NmzCQaDDB8+nPr6+miHKX1UfVMLa8tqKa6oY0NlPSs2V/PKok2sLaslJmCMyEkmOT6WpLgYRuWmcPbB+RwyLIMJQzNUqVJEtpOSEKsiKyIindBTP//3vQRvF5l2JE2bNo2rrrqKLVu28PbbbzN9+nQGDBhAMBjkzTffZM2aNVGJS/qGusYWXlu8iZUlNYDveWtuCbGipIbFG7eyeksNIbetfWzA+NKoHL593EhOOmAQWeqJE5FOSo2PpUpDNEWkN9Hn/+30vQQvSg488ECqqqrIz88nLy+Piy++mDPPPJNJkyYxYcIE9ttvv2iHKL1MKOT4cGUpz326npcWbOzwG/Vh2UnsNyiVM8cPZkRuMvkZieRlJDIgNZ6gCpyIyF5QD56ISOf01M//SvC60Pz528b+5uTk8MEHH3TYTmvgya4s31zNc3OK+Oen6ymurCclPpbTDhrEORPzmTI8CzPDOYeZERNQkROR3sjMEoCZQDz+WfyMc+5n7drEA48ChwKlwFecc6sjGlgoREZcSEVWREQ6qSd+/leCJ9INSqsbWLa5mhUl1azYXENpTQMtIUdLyNEcclTWNX1RyXJLdQMxAePo0TncdNr+nHzAQBKC7deOU2In0ss1AMc756rNLAi8a2YvOuc+bNPmSqDcOTfKzKYBvwa+EtGo7prMtfVDuTn43YjeRkREIkcJnkgXq21sZk1pLQvWV/LJ6jI+XlXG6tLaL44nBmPITY0nNuB74GICRnpikJG5KWQmBxk1IJUzD85jQGpCFN+FiESSc84BrV/nBsOba9fsbOCW8O/PAHeamYXPjYz4VNLqazQHT0SkF1OCJ7KPQiHHyws38tiHa1i2uZqSqoYvjmUkBZk0LIuLphSwf14aIwekkJeWQEBDK0X6PTOLAWYDo4C7nHMftWuSD6wDcM41m1klkA1siVhQiZmkVHQ851dERHqHiCZ4ZjYVuAOIAR5wzt3e7vgw4EEgFygDLnHOFe3NvVrnJPVlkfzSVnZva30T7y3bQjAmQHZKHDkp8cxZW86dbyxn2eZqhmUncdzYXIZlJzMsO4kxA1MZlZuiZE5EOuScawEmmFkG8A8zG+ecW9CmSUf/89jhQWBmVwNXAxQUFOxbUAkZJIWWUd3Q3C+eqyLSu/WH/0/tzef/iCV44W8m7wJOAoqAT8zseefcojbNfgc86px7xMyOB34FXLqn90pISKC0tJTs7Ow++0d2zlFaWkpCgobtdafaxmY+WOErWb62aBMNzaEd2owZmMId0yZwxvjBKnoiInvMOVdhZm8BU4G2CV4RMBQoMrNYIB3/ZWj78+8D7gOYNGnSvn0TmJhBYnMVLSFHfVOIxLj2839FRHoGff7fuUj24E0BljvnVgKY2VP4+QRtE7wDgBvCv78J/HNvbjRkyBCKioooKSnZh3B7voSEBIYMGRLtMPok5xyrttTw9uclvL+ilHVltWyorKeyrgmAzKQg0yYP5cyDBxMXG6C0upGS6gZyUuI4dswA9dKJyB4xs1ygKZzcJQIn4ouotPU8cDnwAXA+8EZE598BJGYS31IFOKoampTgiUiPpc//OxfJBO+LuQNhRcBh7dp8BpyHH8b5H0CqmWU750r35EbBYJDCwsJ9iVX6Ieccc9dV8O/PNvDq4o2sK6sDYHh2EqMGpDB5eBZ5GQnsNyiVo0blEherdeVEpMvkAY+ER7sEgOnOuRfM7OfALOfc88BfgcfMbDm+525axKNKyCDgWkihjur6ZgakRvyOIiJ7RZ//dy6SCV5n5g7ciK8KdgV+PaD1wA4zu7t0foH0S845Nm6tZ01pLWtLa/l8UxUvLdxIUXkdcbEBjh6dw9VHj+SY0bkUZCdFO1wR6eOcc/OAiR3sv7nN7/XABd0ZF4kZAGRYjQqtiIj0UpFM8FrnDrQaAhS3beCcKwbOBTCzFOA851xl+wt16fwC6RdqG5t56uN1LCiuZPnmapZvrqa2seWL47EB48hROVx/4hhOPnAgaQnBKEYrItJDJPgEL50aLXYuItJLRTLB+wQYbWaF+J65acBX2zYwsxygzDkXAn6Er6gpstecc7y4YCO3vbCI4sp6BqUlMHpgChdOGsrI3GSGZSczPDuZwRkJxMZoyKWIyHYSMwFIsxqq1IMnItIrRSzBC6/Zcy3wMn6ZhAedcwvbzS84FviVmTn8EM1vRyoe6XvWltbyyqKNNDSHiI8NEBcb4JWFm3h3+Rb2z0vjjosmMnl4VrTDFBHpPRLVgyci0ttFdB0859wMYEa7fW3nFzwDPBPJGKRvqapv4l9zi/nHp+uZvaZ8h+OpCbHcetaBXHxYgXroRET2VELrHLxqzcETEemlIprgiXSVppYQT328lv99bRllNY2MHpDCD6aO5ayDB5ObGk9jc4jG5hDJ8bEkBFXWW0Rkr4SHaKajIisiIr2VEjzpsWobmymuqGfRhq3c8drnrCip4fARWfxg6n5MHJqx3aKW8bFK6kS6VEsTbFkGlUXb708dBNkjIS453K4ZylbClqXQWAuuBVwInINDLu3+uGXfxCVDIJasQC3lGqIpItIrKcGTHmNdWS1vLNnM60s289m6ii8WGQcYkZvMA5dN4oT9B2yX2In0e85BXTlsXe9/BoIQG+d/bi32iVfJ59BYDWNOgbGnfTHPiq3FsPw12DAPmuuhpdH/LF0JJUsg1LTz+6blQ3walK3w57VnMUrweiMzSMggx9WyrmEXf38REemxlOBJVHywopTnPyumvKaRstpGNm+tZ3VpLQAjcpI5fXweQzITGZyeSH5mIhOGZhDUnDrpT2pKYdkrsPxV/zqzEDKHQ3wqlCyFzQth0yKoXOeTsl1JHgCBWFj0T5/4FX4Zqktg03x/PD7d99zEBCE2HjKGwajjYeA4f08L95C7EGwtgi3LoXQ51FfC6JNgwAGQO9YnjhbYtknvlJhJZoOKrIiI9FZK8KRbNTS38PtXPue+mStJS4hlUHoCWclxHDA4jUsOH8bx+w1gRG5KtMMU6Vj5anjmSkjOhZNvg5xRnTuvYi2s/RCa6nyCFp8KcSkQTIDYRJ9UVW/yiduWz2H9bFj3kU+oUgb5dgv/6Yc/AmCQVegTq7FTfW9aah4kZftet+ZGaGnw5+aO8fOqnIP1c3yS9/lLkDIQTrx1W4LW6Z7xyXvxDye9SmIGmZW1moMnItJLKcGTbvP5piquf2ouizZs5ZLDC/jv0w4gMU5z56QHaayBinW+VyyjwPdKtVr1Dky/zCdZWz6Huw+Hw74Jx/wAEtK3v45zsPpdmPMorHnf93p1VmwCDNgfjv4+jD0V8ib45Kulyc+Hq6+EnNHb5sB1lhkMOdRvJ/9iz86V/iUhgzRbTZV68EREeiUleBIRa0treevzzcxZU86q0lpWb6mhsq6JrOQ4HrhsEiceMDDaIYp4oRb44C744E7fi9bWoPEw/kI/3PDVmyFrJFz0pO+Be/3n/ry5j8PY030yNvI43/P29m9g7Qe+R234l2HYdTDsCN+T1lAFDdXQsNUPrWyq8z+TB/jELaMAAh188RET9L12IpGWmEGaq1IPnohIL6UET7pMZV0T9769gpcXbmRFSQ0Ag9MTGJGbwhnj8yjMSeasCYMZkJoQ5UilR3DOD10sW+mHPpav9olN5nC/JWbB5kVQ/Knfmhv80MiUXD8ksfAYGHoYxHTyf2NN9X7oY+5YSM7x+0pXwD+vgXUfwsgTfI9cxjBIH+LvOW86vPIT33b0KXDe/dt6686+EyZfCe//GRb/G+b+zc9Vcy0+vtN+BxMv9cMrRXqTxEySQ1oHT0Skt1KCJ/vMOcf/zd/Arf9eRGl1A0eOyuHiw4Zx3H4DKMzZw2FkElnOwbqPoao43ItUBfmHQMHh3XP/ugpY+SYsfx1WvLn90MVAEHAQavehMjYR8sb73q+qYtjwGdRshrd/7ZOtUSdC7n6+iEhM0PeujT4F0vK2XWPZqzDj+1C+yr/OLIS8g30Rk0AQ/uNeGP+V7eehFRwOh39rW0GR0Sft2LM2eCKc/6AfPrn2A1+RMrMQJnzVz6sT6Y0SMkgI1VBb1xDtSEREZC8owZN9snRjFbe/uJg3l5YwLj+Nv14+ifFDMqIdluzMu/8Lr9+6/T4LwNTbfe/VnnDO94jNecQnbCkD/RDD7NGQPcIPZ8waATFxsOxl3xu27BVfUj8+HUYcDV++AXLG+qGHqXn+mluLfG9ezRafuOXut2MvXf1Wnyh+/rK/5oJn2wVnvlLkuPN80rX435A9Cs69H6o2+CR33cdQeDSc/gdIz9/5+8wZtftiKjFBf63Co/fs31CkJ0rMIICDxqpoRyIiIntBCZ7sscraJp7/bD1Pzy5iXlElSXEx/PSMA7j8iGHEaimD7hdqgfnP+F6mzOE+WcoaCant5jkue83PGzvgHDjmhxCf4pOvF74LL/7AD1ec+quO53/VlftesNqy8ByySlj+hi/VH0zyvVv1lbD6PZj39+3PjYnzSV3yAJh0JRxwNgyZvPOhla1DNHclIc1f54CzfVIYavHVI0PNfm23Bc/6hPLf1/kewON/Cl/6jnrVRDojMdP/aKmiobmF+FgVwxIR6U2U4EmnhUKOv320hl+/uISaxhb2G5TKzWccwDkT88lKjot2eNG3ebFPLhrDQx9z9/cVCzujtgxWzYSVb/khhkfdAElZ27dZ84Gv7jj4EMge6fctneGTtpIlO15zwsVw0i8gOdvPc3v26zDwQDjn7u0rMH7lMXjlp/DhXb7dxIvDvXAj/Ry4T/7qE6a2a63FJvhrnfFH30uWkLbtWGMNlK3yC2CXrfQ9cSOP93PmOjtfbk+Y+eu2Xjt3LBz3Yzj2R7Bxnk8s2w7XFJFdS/CjMNKpoaZBCZ6ISG+jBE86ZUVJNTc9O49PVpfz5dE5/OCU/RiXn4Z1eu2sXqq5wVdWjInzWzBpx6IZTfXw8o9g1oPb77cAnPVnmHjJzq+/7DV461d+qCMO4lKhqRY+/Ruc8FM45HI/lPDN/4HV72w7LyEDUgb4cv3Zo+DCR2HMVF9Gv3y1H7744V9g6Ytw4i3w0T2AwVf+tmN5/bdvRWcAACAASURBVEAMTP2lH1b54k3bFtZuFUyGgy+CQy7188viUiB2Fwl9XDIMGue3aDLz8+xEZM8khhM884ud6ws8EZHeRQme7FJzS4h7Z67kjteXkRiM4XcXHMx5h+T37cSuudH3pC18Dpb8ny9n39aIY/1Qw7GnQcUamH45bJoPR1wL+58ZXsA6EWbcCP/6NtSWwpHXbX+N0hXw0o/83LSsEb63aeRxvnduy1KY8QN44QZ463afYCYPgKm/huFH+sWq18/21zj8Gl+psbX3Knuk30adAAd/FV64Hv79Xz7ZvOTZXZfZn/wNn8iVLocty/zPlAEw7vzte+hEpG8L9+BlUE1VQ1OUgxERkT2lBE92alHxVn7w7GcsWL+VU8cN4tazD+zbSxy0NMPsh3xSVbvFFwLZ/0wYOsXP7WppgpoS+OzvMP1SXxSkocoX2PjqdBhzyvbXu+jv8I9v+vXTqjbB4AlQstQPp/z8ZT/M8aRfwGH/uX2P2MAD4YoXYOE/YPbDfu7YpCshLskfH3QQHHr57t/PwAPgay/BvKd8z+PI43d/Tlyy7/VSz5dI/xWeg9fagyciIr2LEjzZwcbKeh79YDX3zVxJRlKQuy8+hNMO6uFzmEIhmPE9WPshnHmHT8raWvsRlC7zSU7a4B3PXzXTD0/cvNAvTH3Etb5HraOiHMf9t0/QZj/k1z07/Xd+3bT2YuPgvAf8XLoP7/L7LMb3oh1yKRxz046FUFqZwbhz/bYvAgFfsl9EpLMSt83B01p4IiK9jxI8AaChuYVXFm7i6dlFvLushJCDcyYM5uYzD+z++RdN9bDqbT/3rOhj2DgfTrgZJn294/bO+SqQsx70Q4sePAWOvN4PeyxfBa/d4ouRtMqb4NdOa673wxzLVvi5bOkFfi7b/mdtvx5ae4EY2O80v+1OIMYveH3wRb53LGvkrueviYhEWzCRUEw86c1a7FxEpDdSgtfP1TQ08+THa7n/nZVs2trA4PQEvn3cKM47ZAjDu3qR8tXv+flhqYN23qa+Eh47F9bP8r1dg8ZB+lD4vxt9ZcfCL+94zuu3wif3+163Y34IL/8Y3v0DLHjGFx2JS/EJ4qiT/JpoS1+Ed37vh0hmFULOGD+PbcpVfu5cVzODIZO6/roiIhHiEjJIb6ihSkM0RUR6HSV4/VR5TSMPv7+aRz5YTUVtE0eMyObX543ny6NziQlEoIDKx/f7oiOBoB92ePi3YPDE7du0Jncb5sI598ABZ/ler/pKeOBEePpyuOpNyBzm24dC8M7v/OLdh34NTr7NJ1Nn3wn7nQ6v/gymfBOO/r5fKgAgbzx8+bvQWOsTvIDW7RMRac8SM0jfWsMa9eCJiPQ6SvD6mU1b63ngnZU8/tFaahtbOHH/gVxz3EgOKciM3E0XPQ8zvg+jT/ZDFD99zC+GnT8JDjzHFzJJzNyW3F3wCOx/xrbzE9Jh2pNw//Hw1MVwxb99dcv3/uQrTh50IZz+h+2HVY491W8701qwREREdmCJmaTbVhVZERHphZTg9RNV9U386fVlPPL+GppDIc46eDDfOnYUYwelRvbGa96HZ78BQyb7xC0uCY77kV/n7bMn4ZWf+C0h3S+Q3T65a5UzCs5/EJ64AH43FloaYOBBcO4DvkdQPXEiIl3GEjPICmzQHDwRkV5ICV4fFwo5nvt0Pbe/uITSmgYuOHQI1x43moLsLurBaqqDugpI66DK5tqP4MlpkFEAX/37tl6zhHQ44tt+K1sFS16A5a/DlKt3Xbhk9Im+YMnnL/u2o07YdTEUERHZO4mZZFCrOXgiIr2QErw+xjnHqi01fFZUwWfrKvlwZSlLNlYxYWgGD14xifFDMrrmRnUVvrDJh3/xC3kXHuOLlIw5FYrnwNu/geWvQupgv8B2UlbH18kq9Ou8fek7nbvv5Cv9JiIikZOQQSrVVGuhcxGRXieiCZ6ZTQXuAGKAB5xzt7c7XgA8AmSE29zknJuxw4Vktz7fVMXzc4v597xi1pTWApAYjGFcfhq/PX885x0yhEBXFE/ZvATm/g1mPQyNVX5eXf6hfsjl3y/xyxTUV0BSNpzwM5j8DUhI2/f7iohI90nMIJk66urrox2JiIjsoYgleGYWA9wFnAQUAZ+Y2fPOuUVtmv0EmO6c+4uZHQDMAIZHKqa+aH5RJf/9z/nMK6okYHDkqByuPnoEhw7LZFRuCrExXTA3rbIIFr/g58xtmOuXLzjgbF+NctBBvs2Xb4RlL8P8Z3x1zElfh/iUfb+3iIh0v0RfeMvVVUY5EBER2VOR7MGbAix3zq0EMLOngLOBtgmeA1q7d9KB4gjG06c0NLfwp9eXcc/bK8lJiePWsw7ktIPyyE2N75obrHwbFv8bVr4Jpcv9vkHj4ZRfwUHnQ8qA7dvHxPqlCfY7vWvuLyIi0ZPgh/NbQ0WUAxERkT0VyQQvH1jX5nURcFi7NrcAr5jZd4Bk4MSOLmRmVwNXAxQUFHR5oL3NvKIKvjf9M5ZtruaCQ4fwkzMOID0xuGcXaazxBVBGHAtHfXf7YiWta9YFk2DYkb43btSJkDu2K9+GiIj0VIk+wYupVw+eiEhvE8kEr6MJX67d64uAh51zvzezI4DHzGyccy603UnO3QfcBzBp0qT21+g3mltC3P3WCv70+jJyUuJ56GuTOW7sgN2f2JF3fg+rZvqtcj2c9lsIxMDsR3xyN+ZUuOBhCCZ06XsQEZFeINyDF9ekBE9EpLeJZIJXBAxt83oIOw7BvBKYCuCc+8DMEoAcYHME4+qVVpZU893pnzF3XQXnTBjMrWeP2/Neu1alK+D9P8P4r0DqIHjvDqjZDKNOgn9f53vrLnwEYrtouKeIiPQu4Tl48c1VtIQcMV1RpEtERLpFJBO8T4DRZlYIrAemAV9t12YtcALwsJntDyQAJRGMqVfZtLWelxZsZMb8DXy8uozU+Fj+fNFEzjx48N5f1Dl48QcQmwAn/QJSB0LKIHj5R37OXeEx8JW/KbkTEenPwkM0062G6obmvf9CUUREul3EEjznXLOZXQu8jF8C4UHn3EIz+zkwyzn3PPA94H4zuwE/fPMK51y/HYLZKhRy/Oblpdw7cwXOwegBKXzn+NFcfFgBA9N2M2SydAVs+AwOOAcCHVTQXDoDlr/mi6WkDvT7jrgG0gb7giqn/BKCiV3/pkREBAAzGwo8CgwCQsB9zrk72rU5FvgXsCq86znn3M+7LcjwEM0MqpXgiYj0MhFdBy+8pt2MdvtubvP7IuDISMbQ29Q3tXDj05/xwrwNXHDoEK4+egSjB6bu/sS6Cr+4+Mf3QqgZxvwdzvnL9guMN9XBSzdB7v5+UfK2DjzHbyIiEmnNwPecc3PMLBWYbWavtltGCOAd59wZUYgPYuNojkkivbmGsupG8jP0xZ+ISG8R0QRP9kxFbSNXPzabj1eVcdOp+/HNo0dgtpt5D87BnEfgtVuhrhwOuQyyR8HrP4d7j/aFUlIGwvynYd7foWItXP4CxOjbWBGRaHDObQA2hH+vMrPF+MrT7RO8qAolpJPeUENxZR0HDUmPdjgiItJJSvB6iHlFFVz/1FyKyuu4Y9oEzp6Qv/uTQi1+Pt0nD8DwL/vhlXnj/bHhR8L0K+CvJ4Nr8fuGHgbn3g+FX47Y+xARkc4zs+HAROCjDg4fYWaf4QuU3eicW9iNoRFIzCB9aw3rK+q687YiIrKPlOBFWfulD/72jcOYUpi1+xMba+HZb8DS/4Mjr4MTbtl+zl3+ofDNt2Hm7/xk+YMugKzCiL0PERHZM2aWAjwLXO+c29ru8BxgmHOu2sxOA/4JjN7JdSKyVmxMciaZgTI+LleCJyLSmyjBi6LiijqueXwOc9dVcPaEwfz8rHGkJ+1m6GRLE2yYBy/9EIpmwam/hcOu7rhtUhZM/WXXBy4iIvvEzIL45O5x59xz7Y+3TficczPM7G4zy3HObemgbUTWirXELLJj1lNcqQRPRKQ3UYLXnbYW+0Io+59JZf7RXPbgx2yqrN+29MFbv4ahU2Dkcduf5xx8fD8sfh7Wz4amWr/MwVceg/3PjM57ERGRvWJ+cvVfgcXOuT/spM0gYJNzzpnZFCAAlHZjmJCQQYbVsL6ivltvKyIi+0YJXncIhWDOw/Dqz6BhK6F1H/Ot2N+zprSGR79+GEeMzIb1c+CtX0JcClz1BuSO3Xb+R/f6HruB43wRlaGHwfCjIGVA1N6SiIjstSOBS4H5ZjY3vO/HQAGAc+4e4HzgW2bWDNQB07p9GaHEDFJCVRRrDp6ISK+iBC/Sqkvg6cthzXtQeDQufzKBd39PXcNH3H7++T65A5j9EAST/Bp0T13sk7yENFj5Frz8Yxh7ul+AvKO17UREpNdwzr0L7LJEsnPuTuDO7oloJxIziHMNVFZV09DcQnxsTFTDERGRzlG2EGmzH4I178NZf4bLnufelrOodgn8Yugszjt0iG9TvxXmPwvjzvXLGpSthH992/98+grIGQPn3qvkTkREuk94sfN0atigYZoiIr2GMoZI2/AZZI+EQy7jrrdWcPub65mXeRIHlr3mFycHmD8dmmrg0K/7oZcn/dzPt7vvWHAhmPY4xHdisXMREZGukuQrOmeahmmKiPQmSvAibeM83KDx/O7lpfz25aWcM2EwU87/HtZcB/Om+wIqsx6GQQdB/iH+nCO+DQeeCw1VcP5DPkEUERHpTml+lMlg26K18EREehHNwYukunKoWMsbyadz5+zlTJs8lP/5j4OICRjkTfDDN/MPgU3z4fQ/gIWnZJjBeQ/4nryModF9DyIi0j9l+DX1htgWijVEU0Sk11APXiRtXADAI6vSuOJLw/nVueHkDmDS12DzInjhBggm+4XI2wrEKLkTEZHoSRkIMXGMiS9jfUVttKMREZFOUoIXQcvnfwBA4bgj+NmZB2DWpmjauPMhLhU2zoPxF/iKmSIiIj1FIADpQxkRLFMPnohIL6IEL0KKK+pYPOddyiyTm84/evvkDiA+xSd2AId+rfsDFBER2Z2MoQyhREVWRER6ESV4EdDUEuLaJ+Ywxq0mYehEEuN2snbQ8T/1a9sNntC9AYqIiHRGRgE5LZtYX1FHd6+zLiIie0cJXgTc/uISFqwtYXRgPUkFu0jekrJg/zO7LzAREZE9kVFASnM51lxHWU1jtKMREZFOUILXxd5fvoW/vruK7x7cQsA1++UPREREeqOMYQDka6kEEZFeQwleF6puaOb7z8xjRE4yV46q9jvzDo5uUCIiInsr3Vdz9kslKMETEekNlOB1oV/NWExxZR2/vWA8wZIFEJcCmYXRDktERGTvfLEWXgnrVUlTRKRXUILXFZrqmfPJezz+0Vqu+vIIDh2WBRvnw8Bxvsy0iIhIb5Q6CBcIMjymVD14IiK9hLKPfVVXTsvDZ3DI/53GBZnL+O5JYyAU8gme5t+JiEhvFojB0ocwMq5MCZ6ISC+hBG9fVG2Eh07HFc+l2GVxW8x9JIRqoXwVNFYrwRMRkd4vYyhDAyqyIiLSW0Q0wTOzqWa21MyWm9lNHRz/XzObG94+N7OKSMbTpcpWwYOn4MpX8c2WH/Bkwa3EVxfDa7f43juAvPFRDVFERGSfZRQwMLRJPXgiIr1EbKQubGYxwF3ASUAR8ImZPe+cW9Taxjl3Q5v23wEmRiqeLuUcPH4+1Ffy5P538frH8fzg9KNh7hL48C4oWQoWA7n7RztSERGRfZMxjLTmMqrqq6lvaiEhGBPtiEREZBci2YM3BVjunFvpnGsEngLO3kX7i4AnIxhP19m0EEqXU3fsz/jVvGSmHjiIsYNS4fif+KqZq9+B3LEQTIh2pCIiIvsmXElzsJWyoVKVNEVEerpIJnj5wLo2r4vC+3ZgZsOAQuCNCMbTdZa9AsATZftRVd/MtceP8vvjkuDsO/3vgzQ8U0RE+oAv1sIr0TBNEZFeIGJDNAHrYJ/bSdtpwDPOuZYOL2R2NXA1QEFBQddEty+WvULLoIP58ydVnLj/AMblp287NvwomPYE5O4XvfhERES6Stu18MqV4ImI9HSR7MErAoa2eT0EKN5J22nsYnimc+4+59wk59yk3NzcLgxxL9SVw7qP+DR+MhW1TXzn+NE7ttnvdMge2f2xiYiIdLXUPFwgliGmSpoiIr1BJBO8T4DRZlZoZnH4JO759o3MbCyQCXwQwVi6zoo3wIW4c10hR4/J5eChGdGOSEREJHJiYrG0fEbGlbGuvDba0YiIyG5ELMFzzjUD1wIvA4uB6c65hWb2czM7q03Ti4CnnHM7G77Zsyx7lYZgOjNrh/Gfx4yIdjQiIiKRl1HAyGAZs9eURzsSERHZjUjOwcM5NwOY0W7fze1e3xLJGLpUKIRb9irvMYExg9I5YkR2tCMSERGJvIwCBm9YwprSWtaV1TI0KynaEYmIyE5EdKHzPmfDp1jtFv5VcyBXHlWIWUd1ZERERPqYjAKSGrYQRxPvLNsS7WhERGQXlODtiWWvEsJYkDiJsyYMjnY0IiIi3SOjAMMxPrWad5eXRDsaERHZBSV4e6B+0Ut8GhrFmUccRHxsTLTDERER6R7htfBOGtzAe8tLaQn1jmnzIiL9kRK8zqouIW7zXGa6iVxy+LBoRyMiItJ9wmvhTcmsprKuiQXrK6MckIiI7IwSvE6qWfwyARyBMSeRkxIf7XBERES6T1o+WAxjEyoAeHe55uGJiPRUSvA6acOclyh1qZx8wsnRDkVERKR7xcRCxlCSVrzIlwY2884yzcMTEemplOB1hnNkbv6Q+cHx7D9YC5uLiEg/dOpvoWIt99TdSO2aT6ltbI52RCIi0oHdJnhmdq2ZZXZHMD1V/ablZLeUUDP4S9EORUREJDrGnAxff4n42ABPxt7C8neejnZEIiLSgc704A0CPjGz6WY21frh4m+rZ/m12gcerOGZIiLSj+WNx33jDVYwhIPe+Ras/TDaEYmISDu7TfCccz8BRgN/Ba4AlpnZL81sZIRj6zGalr/FRpfFQeMPiXYoIiIiUZWQlc+f8n/PJsuF5/8LmhuiHZKIiLTRqTl4zjkHbAxvzUAm8IyZ/SaCsfUILtTCkIpZrEw9hPhgbLTDERGRXs7MhprZm2a22MwWmtl1HbQxM/uTmS03s3lm1qO+YZw0toCbGq6ALUvhnT9EOxwREWmjM3Pw/svMZgO/Ad4DDnLOfQs4FDgvwvFFXdHnc8hkK274MdEORURE+oZm4HvOuf2Bw4Fvm9kB7dqcih89Mxq4GvhL94a4a2cePJj3bCJzM06Cd34Pm5dEOyQREQnrTA9eDnCuc+4U59zTzrkmAOdcCDgjotH1AEWzXwagcPLUKEciIiJ9gXNug3NuTvj3KmAxkN+u2dnAo877EMgws7xuDnWn8jMSuXDSUL5Zcj4tcanw/HcgFIp2WCIiQucSvBlAWesLM0s1s8MAnHOLIxVYTxG37l2KAnkMHjYm2qGIiEgfY2bDgYnAR+0O5QPr2rwuYscksPUaV5vZLDObVVLSfevTXXPcKMpI47ncb0HRxzD7wW67t4iI7FxnEry/ANVtXtfQw4aKREpNXT1j6uayOWtKtEMREZE+xsxSgGeB651zW9sf7uAU19F1nHP3OecmOecm5ebmdnWYO5WfkchXJg/lxysPpCFvMrx3h3rxRER6gM4keBYusgJ8MTSzX1QbWTj7HVKtjuT9jo92KCIi0oeYWRCf3D3unHuugyZFwNA2r4cAxd0R25645thRGAGeC54BFWthxevRDklEpN/rTIK3MlxoJRjergNWRjqwnqBi4asADJ90SpQjERGRviK8nuxfgcXOuZ2VoHweuCxcTfNwoNI5t6HbguykweFevF+sGEFLYg7M2s0wTeegfE33BCci0k91JsH7T+BLwHr8N4qH4St69XmZmz6kKFhIfEaPmdcuIiK935HApcDxZjY3vJ1mZv9pZv8ZbjMD/2XqcuB+4Jooxbpb3zp2JM0EeSPpFPj8JahYt/PG7/4B/jRx121ERGSf7HaopXNuMzCtG2LpUaqLlzChZQHzB1/MkGgHIyIifYZz7l06nmPXto0Dvt09Ee2bwRmJfOvYkdz6xhROjH8Cm/MIHP+THRtWbYKZvwfXAus+goyhO7YREZF91pl18BLM7NtmdreZPdi6dUdw0dT4yq00EkvNId+MdigiItKDmdlIM4sP/35seFpDRrTj6k7fOX4UgwrG8I6bQPOsR6ClacdGb94GLY0QEw9Fs7o/SBGRfqIzQzQfAwYBpwBv4yd6V0UyqKgrmk3W6hk80HI6hYUjoh2NiIj0bM8CLWY2Cj+3rhB4Irohda/YmAB/nDaB6XYysbWbaVr0wvYNNs6HOY/BlKsh/1BYrwRPRCRSOpPgjXLO/RSocc49ApwOHBTZsKLIOXj1ZqpjM3k85mzyMxKjHZGIiPRsIedcM/AfwB+dczcA/W7y9pDMJE479zKKXA7rX71r2wHn4OX/hsQMOOb7MORQ2DAPmhujF6yISB/WmQSvdZxFhZmNA9KB4Z25uJlNNbOlZrbczG7aSZsLzWyRmS00s+h/47nsVVjzLn9PuoghA3Pxxc5ERER2qsnMLgIuB1q7roJRjCdqThs/hIV5/8HwrZ9Q8Ycp8Nbt8PH9sOptOPZHkJgJ+ZOgpQE2zY92uCIifVJn1rO7z8wygZ/gyzanAD/d3UlmFgPcBZyEr775iZk975xb1KbNaOBHwJHOuXIzG7AX76HrhFrgtVtwmYXcXX4UJw9Pi2o4IiLSK3wNX3H6f5xzq8ysEPhblGOKmmOu+AV/uyeGsWVvMumt2zEcZI+CSV/3DYZM8j+LZvnhmiIi0qV2meCZWQDY6pwrB2YCezIhbQqw3Dm3Mnytp4CzgUVt2lwF3BW+fmvFzuhZ+iJsXkjlafdS+hyMHZgS1XBERKTnC39x+V8A4S9EU51zt0c3quhJSEjkvGt+ydcf/oQVq1Zw7+FlTDziRIgJd2qm5UNqnk/wDttFIbNlr0LGMMgd0z2Bi4j0EbscoumcCwHX7uW184G2C90Uhfe1NQYYY2bvmdmHZjZ1L+/VNUqWADA/5UgAxg5SD56IiOyamb1lZmlmlgV8BjxkZjtbwLxfSIyL4a9XTGL48BGc/9FI/lXc5nlqtvtCK3Xl8NRX4fm9/QgiItJ/dWYO3qtmdqOZDTWzrNatE+d1NHnNtXsdC4wGjgUuAh7oqLS0mV1tZrPMbFZJSUknbr2XqjdBQjqLt/iJ3/sNSo3cvUREpK9Id85tBc4FHnLOHQqcGOWYoi4pLpaHrpjMoQWZXPfUXO6buQK/vB9+mGbZSqgt6/jkRf/ySyqs+wjWz+m+oEVE+oDOJHhfxy+2OhOYHd46U9+4CGi7iukQoLiDNv9yzjU551YBS/EJ33acc/c55yY55ybl5uZ24tZ7qWojpAxiycYqBqTGk5kcF7l7iYhIXxFrZnnAhWwrsiJAcnwsj145hdMPyuOXM5Zwy/MLaQk5X2gFYP3sjk/87O+QORziUuCje7c/FmqBZ6+CT/4a0dhFRHqr3SZ4zrnCDrbOzMX7BBhtZoVmFgdMwxdpaeufwHEAZpaDH7K5cs/eQheq3gSpA1m6sYqx6r0TEZHO+TnwMrDCOfeJmY0AlkU5ph4jIRjDny+ayNVHj+CRD9bwzcdmU5t7EFgAij7Z8YTyNbD2fZh4CUy4GBY8C1Wbth3/6B6YPx1m3Air3um+NyIi0kvsNsEzs8s62nZ3XnhNoGvxD73FwHTn3EIz+7mZnRVu9jJQamaLgDeB7zvnSvf+7eyjqo2EUgaxbHM1YwcqwRMRkd1zzj3tnBvvnPtW+PVK59x50Y6rJwkEjB+ftj+3nnUgbyzZxEUPL6A5e6wvtNLe/Kf9z4Mu8Aujh5pg9sN+X/lqeOM2GHk8ZI2EZ6+E6ujWZxMR6Wk6s0zC5Da/JwAnAHOAR3d3onNuBjCj3b6b2/zugO+Gt+hyDqo3sTUmi8bmkHrwRESkU+z/27vv+Crr8//jrysne09GSMIMyFBWRECGAxQXtEoV96baWqutbb8d2l8dHWpbta6i4mjdq6LiXjgQAVH2npEVVibZn98f9wEiBAiQk5PkvJ+Px/3Iuce5z3Xf3OST63yWWRbwL+B4vL7mnwE/d87lBzWwZujSoZ3ITI7hZ89+zdTILM4ononPOW/gFfDK4rnPQ84Qr4kmQLfRMOsxGHYjvPELr+bvrPugvBAePRlevgoufhXCfEG7LhGR5qQhTTR/Vme5GugPtL7OaeU7oLqcDTVJABylETRFRKRhHsfrgpCJN1r06/5tUo/Rvdry3MQhfOu64avYwYxZX+3ZueFb2LIUjjl3z7bB13hdKF66HFZ8ACffAsnZ0K4PnH6XN4n6e7fAio9gyduwcMr+B28REQkBDanB21sZ9QyE0uL52/evrEjADLq10Rx4IiLSIBnOuboJ3RNmdkPQomkB+mUn03bCufDMQzz36qs8sjCM35/Ri85zXwBfJPT+4Z6Du5wEabmw+A1vcJZjr9qzr//FsOYLmH6/t+yS2gUufwsS2jXdRYmINBMHTfDM7HX2TG8QBvQCXghkUEFRshGAJSWxdEqLIyZSTT1ERKRBtpjZRcCz/vXzgeD1J28h2nfri4tK4NaoV3ly5VYm/nMwr8Y+R0zXU/DFpOw5MCwMjr8epv4axt73/aaYZjDuARhwCWAQHul9YfvyVfDkWLjsTYgP4OjbIiLNUENq8O6u87oaWNMq+xX4a/Dm7IimR3v1vxMRkQa7Argf+CfeF6JfAJcHNaKWIMyH/egJEj67h+tWv8B1ES9AFfxxbR/OXreDvtl1psXtfzH0OQci4+o9Dx2Hfn/bhS/Af8fDf34Al74OsQ2ZvldEpHVoyDx4a4EZzrlPnHOf44162SmgUQWDvwZvzvYoDbAiIiIN5pxb65wb65zLcM61cc79A1VUWgAAIABJREFUAG/SczmYbqPgsjfgxgUw6k9s7HYeH9X255yHvuC+D5ZRXVPrHWdWf3K3P52GwfnPwpZl8J8fQmkDKlR3boea6sO7DhGRZqQhCd6LQG2d9Rr/ttaleBM14bGUuBgleCIicqSCPzp0S5KUBcNuoN1Fk3j9hpM545j2/OO9pYy862P++d5S1m0rO/Rzdj0RJjwNBYvh8TGwY92+xxRvghmTYPJp8LfO8P4fj/xaRESCrCEJXrhzrnLXiv916xtFs2QjZVHpAHTXHHgiInJkLNgBtFRJsRHcO6E/j1ySR5eMOO77cBnD7/yISyZ/xfLNxYd2stzRcNErULwRJp8KBUugtgaWvgNPnwt/7wFv/cobSbv9MTD7Sag4xM8QEWlmGtIHr8DMxjrnpgCY2ThgS2DDCoLiTRSHpwGQmRwd5GBERKSFcwc/RA5kdK+2jO7VlvztZbw0O58nvljN6fd+xs9H5TJxRBcifA35jhrodDxcPhX+c7aX5EUlwI61EN8Whv8Sjh4PbXrCupnw2ChvHr66I3WKiLQwDUnwrgGeNrNd4w/nA5cELqQgKd7A9rBOxEb6iI08nNkjREQklJhZMfUncgbENHE4rVZWSiw3jOrOhcd15I9T5nPXO0uYOm8DvxlzFMd3S8cX1oDK0nZHw5XvwHMXeQOujL4VjjoTfBF1PigP2veFrx6FvCv3TL4uItLCHDSTcc6tAAabWTxgzrnW2XahZBMFcf1Ij48KdiQiItICOOfUnr8JZSRE8eCFA3l7/gZufm0Bl0z+ijYJUZzVN5OzB3Sgd2bSgU+Q2gV+8sX+95vBoInw2k9h9WfQeXjjXoCISBM5aPsGM/uzmSU750qcc8VmlmJmtzdFcE2mogQqS9hYk0xafOvrXigiItJajOnTnk9/fSIPXTiA/jnJPDV9NWfc9xmXP/4Vc/N3HNnJ+5wDMSkw85E926rKYdpdsH7OkZ1bRKSJNKQB+2nOud2/MZ1z24HTAxdSEJR4c+Ctq04kLU41eCIiIs1ZdISP045uz78vzmPm70fx6zE9+HrtDsbe/zlXPzWLZZsOs7FRRAz0vwgWvQFF673lidPhw9vhhUuh8jBG8xQRaWINSfB8ZrY76zGzGKB1ZUHF3hx4qysSSFcNnoiISIuRHBvJT07oxme/OZEbR3Xny5VbOe3eT/nL1EWUVhzGvHZ5V4Krhbf/D/49EjYvhhG/gh1rYNqdjX8BIiKNrCEJ3n+BD8zsSjO7EngPeDKwYTUx/yTnK8rj1URTRESkBUqIjuDno3L5+KYTOHtAB/49bSWj/vEJb83bgHOHMKhpamfIPQUWvgZR8XD1B3DSH6DfRfDFv2DTwsBdhIhIIzhoguecuxO4HegJ9ALeBjoGOK6mVew10dxQk6xBVkRERFqwtPgo7hzfl5evHUJSTATXPv01Fz/21aE12xz9JxhyHVz9oTeFAsApt0F0ErxxA9TWBiZ4EZFG0MBJZNgI1ALnACcDiwIWUTCUbKTWF0UhcaQpwRMREWnxBnZM5Y2fDeNPY3szN38HY+79lFtfX8iWkoqDv7lNTzj1Dm/AlV1iU+GU22HdDPi6dTVkEpHWZb/TJJhZd2ACcD6wFXgeb5qEE5sotqZTvJHK6HQoNdLj1ERTRESkNQj3hXHp0E6c1TeTu99dwuNfrOLJ6asZ2jWNM49pz6m925Ecewjlft/z4Ztn4M1fwlePQLs+0LYP9LsA4tIDdh0iIofiQDV4i/Fq685yzg1zzv0LqGmasJpY8UZ2Rnm/mFWDJyIi0rqkxkXy5x8ezXs3juCakV1Yu62M37w8j8F/+YC731lCSUMHYzGDcx6DYTdAUgdY9Sm8dzM8cx7UVAX2IkREGuhAE52fg1eD95GZvQ08B1iTRNXUSjZRFJ4JoEFWREREWqlubRL41alHcdMpPZj/XRGTPl3J/R8t57mZ6/jF6O6cm5dFuO8gvVcS2sLJt+xZn/8yvHSFN1feib8L7AWIiDTAfn+LOededc6dBxwFfAzcCLQ1s4fM7JQmiq9pFG9ke1gqYQYph9JUQ0RERFocM+PorCT+dX5/Xv3JUDqlxfK7V+dx2r2f8v7CTYc26mafc7ymm9PugrUzAhe0iEgDNWQUzVLn3NPOuTOBLOAb4P8CHllTqSqH8h1sdsmkxkXiC2udlZQiIiKyr/45Kbx4zRAeunAA1bWOq56axXn//pI5a7c3/CSn3QlJ2fDKVVBeFLhgRUQaoKGjaALgnNvmnPu3c+6kQAXU5Er2TJGQFqf+dyIiIqHGzDjt6Pa8e+MIbvtBH1ZuKeXsh77gtjcWUl7VgOEHohPhnEeh8Dt48xeaRkFEguqQErxDZWZjzGyJmS03s31q/czsMjMrMLNv/MtVgYynXv4Eb111ovrfiYhIkzCzyWa22czm72f/CWZWWKd8vKW+46RxRfjCuHhwRz751QlcPLgjj322ijP/9Rlz83cc/M3Zg+CE38K8F+GZc6FsW+ADFhGpR8ASPDPzAQ8Ap+FNkH6+mfWq59DnnXP9/MujgYpnv4o3ArC6PF4jaIqISFN5AhhzkGM+rVM+3toEMYlfXFQ4t47rw3+uHERJeTU/fPAL7vtgGTW1B+mbN+ImOOPvsPJjmDQS1s/xavO2LIdvn/cWEZEAO9AomkdqELDcObcSwMyeA8YBCwP4mYfOn+At2xnPSarBExGRJuCcm2ZmnYIdhxzY8NwM3rlxBLe8Np9/vLeUz5dv4Z4J/WifFFP/G8zg2KugfX944RJ47BSIiIHywj3HxGdA19bT00VEmp9ANtHsAKyrs57v37a3c8xsrpm9ZGbZAYynfiUbceZjbUUs6arBExGR5mOImX1rZm+ZWe/9HWRmE81slpnNKigoaMr4QkJSTAT3nNePv/+oL/O+K+S0ez/l3QUbD/ymrIHw42neBOi9z4ax//LWU7vAW7+B6sqmCV5EQlIgE7z6hqPcu23D60An59wxwPvAk/WeKJCFV/EmamMzcISRFqcaPBERaRa+Bjo65/oC/wL+t78DnXOTnHN5zrm8jIyMJgswlJgZ5wzM4o2fDSMrJYaJ/5nNnW8vPnCTzbg0OOteOOseGHAJtO8LY/4KW5bCjIebLngRCTmBTPDygbo1clnA+roHOOe2Oucq/KuPAAPrO1FAC6+SjVTEeOdUHzwREWkOnHNFzrkS/+upQISZpQc5rJDXJSOel68dyvmDsnnw4xVc+eRMCsuqGn6C7qdC7qnwyd92dxEREWlsgUzwZgK5ZtbZzCKBCcCUugeYWfs6q2OBRQGMp37FmyiL9MpMjaIpIiLNgZm1MzPzvx6EV15vDW5UAhAV7uMvZx/DHT/sw+fLtzD2gc9Yvrmk4ScY8xeoqYT3/hi4IEUkpAUswXPOVQPXAe/gJW4vOOcWmNmtZjbWf9j1ZrbAzL4FrgcuC1Q8+1VaQJEvBYAM1eCJiEgTMLNngelADzPLN7MrzewaM7vGf8h4YL6/fLwPmOCcO8gQjtKULjyuI89ePZjSimrOf+RLVhY0MMlL6wpDroO5z8HyDwIbpIiEJGtp5UVeXp6bNWtW453wjky+aftDfrD8dBbeeiqxkYEcWFRERA6Fmc12zuUFO46WotHLSDmoZZuKmTDpSyJ8Ybzw4yHkpMUe/E2VpfDvEbB9NYy+DQZf643AKSLSQAcqHwM60XmzV1sDVaUU1UQRE+FTciciIiKHJLdtAv+96jjKq2s4/5Ev+W7HzoO/KTIOrvrA64/3zm/hxUuhvCjwwYpISAjtBK/Sa06xrSZK/e9ERETksPRsn8h/rjiOovIqzp/0Jeu2lR38TTHJMOFpGH0rLHoDHhwM7/we1n7pTY4uInKYQjvBq/ASvK1VkRpBU0RERA7b0VlJPHXFIAp3VnHOQ1+wZGPxwd9kBsf/HC57E9r0hBn/hsmnwt97wCs/hm+egcL8wAcvIq1KiCd43i/fgspIMlSDJyIiIkegf04KL/x4CGbwo4e/YPaabQ17Y8chcNHL8OsVcM5j0Hk4LH8P/nct/LM3PDp6998sIiIHE9oJnr+J5sbycNLiVIMnIiIiR6ZHuwReumYoqXGRXPjoDD5asrnhb45OgqPHw/jJcNNyuOZzGPX/4LtZ8PrPoYUNjCciwRHaCZ7/27CN5RHqgyciIiKNIjs1lpeuHUq3NvFc/eQsXp1zGM0sw8KgXR8YdiOc9AeY/zLMeqzxgxWRVkcJHlBYG60+eCIiItJo0uOjePbqwQzqnMqNz3/Lo5+uPPyTHX8jdBsNb/8W1n9T/zHOwZynYfuaw/8cEWkVQjvB8zfRLCGadNXgiYiISCNKiI7g8cuP5fSj23H7m4v489RF1NYeRjPLsDD44b8hLsObUmHnjn2P+fA2eO0n8Php3vx6IhKyQjvB89fglbgY0lWDJyIiIo0sKtzHv84fwMWDOzJp2kqufXo2pRXVh36iuDQY/7g3qubjp8PWFXv2zXocPv079DzLm0T9ybNgx7rGuwgRaVGU4AGlxKgPnoiIiASEL8y4dVxvbjmzF+8t3MT4h6c3bEL0veUcBxc8D8XrYdKJsOQtWPouvPlLyD0Fxj8BF7/q1fA9eRYUbWj0axGR5i+0E7zKEmosnEoiNIqmiIiIBIyZccWwzky+7Fjyt5Ux7v7Pmbm6gdMo1NVtFEz8BFI7wbMT4PmLvMFYxj8OvnDoMAAuegVKC+A/P4Tqika/FhFp3kI7wasoptIXhxmkxEYEOxoRERFp5U7o0YZXfzqU+CgfEyZ9yUMfrzj0fnkpHeGKd2DApZDeHS54EaLi9+zPPtabaqFgEUx/oHEvQESavRBP8ErYGRZLSmwk4b7QvhUiIiLSNLq1SeD1nw1jTJ92/O3txVzx5Ey2lVYe2kkiYmDsfXDtZ5DQdt/93U+FHmfAtLuhaH3jBC4iLUJoZzUVxZQRoxE0RUREpEklREdw//n9uf0HffhixVbOuO9Tlm4qbtwPOfUOqK2Gd2/+/vY10+HLh6CkoHE/T0SahdBO8CqLKXHR6n8nIiIiTc7MuGhwR165dig1tY7xD33BV6sOo1/e/qR2huN/DvNfgtWfQ001fHiHN5XC2/8H9/SB12+ALcsb7zNFJOhCO8GrKPFPcq4aPBEREQmOPh2SeOUnQ0lPiOKix2bw9vyNjXfyYTdCUjZMvckbWXPandDvAm+glmPOg2+egfvz4NVrNeqmSCsR4gleMYW10STFaIAVERERCZ6slFheumYovdon8pOnZ/PAR8upOZxJ0fcWGQun3A6bF8LGuXD2I/CDByGzn9eH78b5MPRnXi3fvwZ68+lVlR/554pI0IR2gldZQmFNFPFR4cGOREREREJcalwkz1x9HKf1ac9d7yxhwqTprNtWduQn7jXOS+x+PA2OOff7++LbwCm3wU9nQNcT4YNb4b5+Xr+9jfOP/LNFpMmFdILn/DV4sZFK8ERERCT4YiPDuf+C/vzj3L4s3lDMafd+ykuz84/spGZeYpfWdf/HpHaBCU/DJVOgfT/48kF4+Hh4cCjkzz6yzxeRJhW6CV5tLVZZQikxxEX5gh2NiIiICOANvnL2gCzeumE4vTMTuenFb/nja/OpqqkN/Id3GQkXPAe/XAqn3w0VRd6E6oXfBf6zRaRRhG6CV1UKQLGLIU5NNEVERKSZyUqJ5ZmrBzNxRBeenL6GSyd/xfZDnS/vcMWlwaCr4cKXoGonPHeB91NEmr3QTfAqvLlmSokmNlI1eCIiItL8+MKM353ek7t/1JdZq7fzgwc/Z27+jqYLoM1RcM6jsOFbeO06cI0w8IuIBFRAq67MbAxwL+ADHnXO/XU/x40HXgSOdc7NCmRMu1WUAFDqYohTHzwRERFpxsYPzKJLRhzX/Gc24x74nB8NzOJXpx5FRkITzOXbYwycfLM3AEtMCuQMhphkiIiDTfNh3QxY+6X35Xnn4dD1JG9J6RT42ERkHwHLbMzMBzwAjAbygZlmNsU5t3Cv4xKA64EZgYqlXv4avGJiiFUfPBEREWnmBuSk8P4vR3L/h8t5/PNVvDVvIzeM7s7lQzsRFmaB/fBhv/AmRJ/5iLfUldAeso+DyDhY+TEset3bftLNMOKmwMYlIvsIZNXVIGC5c24lgJk9B4wDFu513G3AnUDT/gao9DfRdNGqwRMREZEWITE6gt+d3pMJx2Zz6xsLue2NhXy+fAv/OLcvybGRgftgM2/+vNG3ws7t3lJRBOm5kNzR2w9eE84ty+Djv8CHt0FcBgy8NHBxicg+AtkHrwOwrs56vn/bbmbWH8h2zr0RwDjq56/BK9EomiIiItLCdMmI5/HLjuXWcb35dFkBZ9z3Gd+uC3DfPDOIz4CM7pBzHOSO9pphmn3/mIzucPYk6HoyvHEDLHkrsHGJyPcEMsGrr63A7p65ZhYG/BP45UFPZDbRzGaZ2ayCgoLGic7fB89L8FSDJyIiIi2LmXHJkE68dM1QAMY//AWTP1uFaw4Dofgi4NynvDn1XrzM66NXn6pyb0L1FR/B3Bfhq0dg/RwN5iJyBAKZ2eQD2XXWs4D1ddYTgD7Ax+Z989MOmGJmY/ceaMU5NwmYBJCXl9c4/+Mrdw2yoonORUREpOXqm53Mm9cP46YXv+XWNxby2fIt3DX+GNLim2AAlgOJiocLX4THRsPkMd7AK/0vgh6nw8a58M3TMP9VqCjc971J2dDzLO/Y7EEQ7r+WmmpY/Dp8cT/UVsOEZyCpw77vFwlhgcxsZgK5ZtYZ+A6YAFywa6dzrhBI37VuZh8DNzXdKJpFgFeDp2kSREREpCVLjo3kkUvyeGr6Gu6Yuogx937K3T/qy8juGcENLC4drngHZj4Kc56Gly6HsAiorYLwGOg1Frqf6g3UEpcBETGw8hNvoJaZj8GXD0JELHQcCu2OgQWvwPbVkNIZSrd4yeNFL0ObnsG9TpFmJGAJnnOu2syuA97BmyZhsnNugZndCsxyzk0J1Gc3SEUJNebDhUcR4Qvd6QBFRESkdTAzLh3aiUGdU/nZs3O4dPJXDM9N58bR3RmQkxK8wOLbwIm/g5G/8UbZXDLVa7rZaxxEJ+57fP8LvaWiGFZN896z8mNY/j5kHQujb4OjzoBNC+Dp8TD5VDj/OW/fjrWwbRUk53h9AUVCkDWLdtqHIC8vz82a1QiVfG/eRNnXz3O8e4w5t5xy5OcTEZFGZ2aznXN5wY6jpWi0MlJavPKqGv775Roe/HgF20orObFHBrec1ZvO6XHBDu3wVRRDZPz3B3XZvgb+ew5sW+mtuxrvpy8Kzn8Wup3c9HGKNIEDlY+hW3VVWUJ5WKz634mIiEirEx3h46rhXfj01yfy6zE9mL1mO+Pu/4xPljbSYHXBEJXw/eQOIKUjXPkuDL4Wht0I4x6ES6Z4tXfPXeAN3iISYkI3wasoZqfFEK8RNEVERKSViosK5ycndOPN64eTmRzD5Y9/xSPTVjaPkTYbS2wqnHoHnHyz17Szy0i4+DVI7QrPnu818wRvZM7yQlg7Az77Jzx9LvxrIMx7KbjxizSy0M1uKoopJYZYzYEnIiJNzMwmA2cCm51zferZb8C9wOlAGXCZc+7rpo1SWpPs1FhevnYoN734LXdMXcTc7wq5+YyetEmMDnZogRGXBpdOgSfOhP+O9wZ7KS2Amso9x6Tlgi8SXr7KG1194GX7P9+qaV5tYGWpt7habwL3nMEBvxSRQxW6CV5lCaXEEKcmmiIi0vSeAO4HntrP/tOAXP9yHPCQ/6fIYYuLCueBCwbwwEfLue/DZby/cBNXj+jCxBFdWmeLprh0L8n74Fav9i4uzRupM6UTZA/2Jm2vLIMXLoHXf+7NkTz0uu+fo6YKPrwdPr8HwsIhMs7rB1hZCt8+A33OgVF/guTsekMQCYZW+L+5gSqKKXYZmiJBRESanHNumpl1OsAh44CnnNeO7kszSzaz9s65DU0SoLRaYWHGz07OZWy/TO56Zwn3fbCMZ2as5doTunLBoBxiWtvfRfFtYNz9+98fGevNpffK1fDu772RObudDB0GepO1v3QFrJsBAy+HMX/xpnEAL8H7/F5vWTwVup4IVWVekuhqvOP7XwRhrex+SosQwgleCUW12cS1xm+sRESkpesArKuznu/fpgRPGkXHtDjuv2AAVw7bzp1vL+G2Nxby4EfLuWp4Fy4anENCdESwQ2w64ZEwfjK83Qa+fsqrmQPAvBq7cx6Do8d//z2Rcd7UD/0v8mr4Ns7zavaiE735+V6/3pv777S/eXP47dwOBUugMN+rQWzT0zuHSACEbnZTWUJhbbRq8EREpDmyerbVOyqGmU0EJgLk5OQEMiZphfrnpPDsxMHMXL2N+z9czt/eXsykaSu4YVR3LjguJ3TmCg7zwel3wal/hs0LIX8WbF8FAy6D9G77f19yDpw96fvbnIP5L8N7t8Djp0FsOpRt2euNBmldoU0vL9nL6AFt+0B6931HChU5RKGZ4DkHFcXsqI1qnW3ORUSkpcsH6nbqyQLW13egc24SMAm8efACH5q0Rsd2SuXJKwbx7bod/O3txfxxygKemr6a35/RkxN7tMFCJenwRUD7vt5yuMy8Gr8ep8OMh2DrSi+By+gBSdnenH2b5nu1fpsWwOI3vEFbALIGwfBfQO6pEHaEyXX+bC/RjE31ag2TO0Jipre+q6mptEqhmd1UlgKOwpooDbIiIiLN0RTgOjN7Dm9wlUL1v5Om0Dc7maevOo4PFm3mz1MXccUTsxiem84tZ/Yit21CsMNrWSJjYfgv993ethf0PHPPelU5bF0Gqz+HLx+AZydARk8YcRP0Pvv7iV55EXxxH2yYCziv0sIXCZn9odPxXt/BjfPhk7/CsnchLAJqq/aNISIWkrLg9Lu9aSWkVQnN7KaiGIASYmmjaRJERKSJmdmzwAlAupnlA38EIgCccw8DU/GmSFiON03C5cGJVEKRmTGqV1tG9sjgP9PXcM/7Sxlz76dcMqQjN4zqTlJMCPXPawoR0dDuaG859kqY/4o3T9/LV8Kn//Dm98s9Bb59Ft7/E5RuhrZHe81KzbyRQJe86Z3LF+lNBRGTCif/EQZdDRjsWAs71kDJJijbCmXbYOk78N+z4bQ7vc/dpWAprJ7m1SJqdNAWKTQTvMoSAEpcNLGqwRMRkSbmnDv/IPsd8NMmCkekXhG+MK4Y1plx/TL5+3tLeeKL1bzy9XdcNrQTlx/fieTYyGCH2Pr4IqDveXD0j2DBK/DRHV6NXmyal5hlDYILnvNq6uoq2wZrp8OaLyC+LeRdDlF1alzb9vKWukb+xksi3/wFFCz2ksgZD8Py97399iuvmelx10CnYfv2Ddy+Gt7+LSS0g1Pu8Gos91ZVDis+gAWvwpalcNLNkDv6iG+THJh5ZUjLkZeX52bNmnVkJ/nua3jkRK6ovIlx517BuH4dGic4ERFpVGY22zmXF+w4WopGKSNF9mPB+kLueX8Z7y3cRFykj4uGdOTHI7qSGqdEL2BqquCbp2HhFOh7vte3rzH7Q9bWeIPBTPdPJRHfFo69CrqP8RLM2U94I4Bm9IS8K7zkMzIBZj4C7/8/7z1VZd4AMec+5Q0cA14z0RkPwYLXoLIYYlIgOtkbuGbIdV7tYvh+npuybV5ccekacOYADlQ+hmaCt/ITeGos51XczNUXX8yoXm0bJzgREWlUSvAOjRI8aQqLNxbxwEcreHPueuKiwrnuxG5cdnwnosLV7aXFWjjFa9rZc+z3E6+qnTDvJZj1GKyf4/XdS+nkjTTabTScdQ9sXuTNI1hb4/UbXP4+rJrmHdv7bOjzQ+g8Emqr4d0/eNNHZA6A0X/ymqXGpHh9Cdd+6SWOC6d4/QYjEyC1szfK6IBLvekm9pfw1dZ6fQ7jM/at3WyllODtbfGb8NwFnFFxB7+/agJDu6Y3TnAiItKolOAdGiV40pSWbSrmz1MX8dGSArJSYvjZSd04oUcb2iZGBzs0CYTvvobZj8O6mXD89V6N4q6Ea8c6ePFS+G42JGTCcRO9pCw2dd/zLJwCU66D8kJvPSkbwqO9gWaikqDfBV4SuW2lt3w3y6tFzOzv1f71PAvCo/acb9Wn3iT1G7711o86E076g5cYtmIHKh9DswPa7kFWYjSKpoiIiMhhyG2bwOOXD+KzZVu4/c2F/ObleQB0zYhjaNd0Lju+E10z4oMcpTSaDgO8pT7J2XD527BpHrQ7xutLuD+9xkLn4d40Dpvmec05Swtg6HVe38O9J4Cv2ukNMDP9Aa/PoPkgrZuXwFWVeTV3iVnwg4ehcB18fh8smQp9xsNRZ0DnEd9PNKsrvfE49k4+a6q9ZHLbKm9k0cTMw7tPzUBoZjf+BK/UxRCnUTRFREREDtuw3HSmXj+chRuKmL5iK1+s2MJLs/N5fuY6fnJiV649oauab4aC8MiGN4+MSYHcUd5yMBExXv+/AZd5zT/XzfCahW6c69UCnnwLDP7Jnrn98q6Ez/4Bs5+EeS8ABu36QHiMlwAWbwQcxGV4fQfb9vYGjFk1DSqK9nxu5gAvQWzbG6KTvCUmxeunGLbX81xb6zUrrVuzGEShmeD5R9EsJkajaIqIiIgcobAwo0+HJPp0SOLqEV0oKK7g9jcXcs/7y5jy7XpuPqMXw3PTCfcd4eTdErrCwqD7Kd5yIHFpcOodMOr/ec1KV30Cqz/19nU9yWsSGhkHBUu8GsSvHoH4NtD7h9DtZEjp7CWSi9+ED2/b9/zm80YOTcyE6gqv9rG0wOtjGJvmnT852zuustSrZaypBF+UlwSHR0OvcdB3QmPfod1CM7upKKbWfFQQoSaaIiIiIo0sIyGKeyf05+wBWfzhf/O4/ImZJMdGMKpnW07t3Y4TemQQoWRPAskXATnHecvIX+//uNpary9h3QFc2h8Dw38BJZuhMN+rKSwvhLItULQBitZD0XfefIO8ggDSAAAW10lEQVTtj/Fq9cJjoCjf649YsNQ7T2QsRMRBZLw3Imp5EVQXeCOFBlBoZjcVJVT64gAjVk00RURERAJiZPcM3rtxJB8v2cw7CzbxzoKNvDQ7nw7JMVwzsgs/yssmOkJ/i0kQhR3gi4b4Nt7SwoRogldMRVgskeFh+vZIREREJICiI3yM6dOeMX3aU1ldyydLC3jo4+Xc/NoC7v1gOZcO6ci4fh3ISatnomwROWShmeBVFlMeFkNcpL4xEhEREWkqkeFhjO7VllE92/Dlym08+PFy/v7eUv7+3lL6ZiVx5jGZjO2XqakWRI5AaCZ4FSWUWawGWBEREREJAjNjSNc0hnRNI397GW/O3cAbczdwx9RF/OWtRYzonsH4gVmM6tlWTThFDlFoZjgVxZShKRJEREREgi0rJZYfj+zKj0d2ZdWWUl6enc/LX+dz3TNziI4Io192Msd2SuXYTqkM6Zqm7jUiBxHQBM/MxgD3Aj7gUefcX/fafw3wU6AGKAEmOucWBjImACpLKCVDNXgiIiIizUjn9DhuOrUHN47uzhcrtvDR4gJmrdnGgx+voKZ2OVkpMVwzsivjB2apZk9kPwKW4ZiZD3gAGA3kAzPNbMpeCdwzzrmH/cePBf4BjAlUTLtVFFPssomPUoInIiIi0tz4wozhuRkMz80AoLSimk+XbeHhT1bwh//N574PljFxRBcuOC5HX9iL7CWQddyDgOXOuZXOuUrgOWBc3QOcc3WmiycOcAGMZ4+KEopro4nVICsiIiIizV5cVDhj+rTj1Z8M5ZmrjqNbm3huf3MRx//1Q+7/cBmFO6uCHaJIsxHIrzw6AOvqrOcDx+19kJn9FPgFEAmcVN+JzGwiMBEgJyfnyKJyDiqL2eGLJk41eCIiIiIthpkxtFs6Q7ulM3vNdh74aDl3v7uUhz9ZSV6nFHq1T6R3ZhL9c5LJTI4JdrgiQRHIDMfq2bZPDZ1z7gHgATO7APgDcGk9x0wCJgHk5eUdWS1fVRm4WgprolSDJyIiItJCDeyYwuTLjmX+d4X8Z/oavs3fwafLtlBT6/2peFS7BEb1bMuoXm05pkMSYWH1/Wkq0voEMsHLB7LrrGcB6w9w/HPAQwGMx1NRAsC2mijV4ImIiIi0cH06JPG38ccAUF5Vw7JNJUxfuYX3F23mwY+Xc/9Hy2mfFM2YPu044+j2DMhJUbInrVogM5yZQK6ZdQa+AyYAF9Q9wMxynXPL/KtnAMsItIpiAHZUR9FZNXgiIiIirUZ0hI+js5I4OiuJiSO6sqOskg8Xb2bqvI08PWMtj3++mpzUWK4e0YUfaSROaaUCluA556rN7DrgHbxpEiY75xaY2a3ALOfcFOA6MxsFVAHbqad5ZqOr9BK8UmI0iqaIiIhIK5YcG8nZA7I4e0AWxeVVfLBoM098sZqb/zefe99fxuXHd2Jo1zRy2ybo70JpNQL6JDvnpgJT99p2S53XPw/k59fLX4NXQoyG1RUREREJEQnREfygfwfG9cvky5XbeOiTFdz1zpLd+zOTohnYKZVz87I4vmu6mnFKixV6GY6/D16JiyYuStXyIiIiIqHEzBjSNY0hXdNYt62MxRuLWbqpmGWbivlkaQGvf7ue7NQYzh2YzfG56fTOTCQqXH8zSssReglepT/BUw2eiIiISEjLTo0lOzWW0b3aAlBRXcM7Czbx3Fdr+ft7S/n7e0uJ8Bm92icytFs65wzIolub+CBHLXJgoZfhRCVSnDGAonVxxGmQFRERERHxiwr3MbZvJmP7ZrKpqJw5a7czZ90O5qzdwaRpK3no4xUMyElm/MBsTuiRobn2pFkKvQSvxxhmuv5se2KWpkkQERERkXq1TYxmTJ/2jOnTHoDNxeX8b853vDgrn9+9Og+ArJQYBnVO5dhOqQzsmEK3jHj13ZOgC8kMp6SiBkB98ERERESkQdokRDNxRFeuHt6FhRuKmLFyGzNXb+OTJQW88vV3ACREh9M/J4XjOqcyuEsqR3dIJjI8LMiRS6gJyQSvrKIaQH3wREREROSQmBm9M5PonZnEFcM645xj9dYyZq/ZztdrtzNr9bbdo3PGRPg4tnMqI3LTGZ6bQfe28Ziphk8CKyQznNJKfw2eEjwREREROQJmRuf0ODqnxzF+YBYA20or+WrVVqav2MrnK7Zy+5uLgEW0SYiif04yx2Qlc0xWEn2zk0mMjgjuBUirE5IZzq4avBgNsiIiIiIijSw1LvJ7/ffW79jJZ8u28PmKLczNL+SdBZsA8IUZA3KSGdk9g5Hd29CnQ6Jq+OSIhWSCV1pZQ6QvTG2iRURERCTgMpNjOPfYbM49NhuAwrIq5n1XyJcrt/LJ0gLufncpd7+7lA7JMZzWpx2nH9Oe/tnJSvbksIRkgldWWa0BVkREREQkKJJiIxiWm86w3HRuOrUHW0oq+HhJAW/N28CT01fz6GeriPSFkRIXQUpsJG0SoznrmPac1TeT6Aj9DSsHFpIJXklFtQZYEREREZFmIT0+ivEDsxg/MIvCnVV8sGgTSzeVsL20km1llazYXMKvXprLHVMXcV5eNqcd3Z7O6XEkxaj/nuwrJLOcsooa1eCJiIiISLOTFBPB2QOyvrfNOceXK7fx1HSvdu/f01YCkBIbQU5aHG0SokiPjyIjPpKubeIZ1i2dtPioIEQvzUFIJnillarBExEREZGWwcwY0jWNIV3T2FRUzrfrdrB6aymrt5axbpu3zFm7na2llTjnvadPh0SG52YwsnsGAzumEOHT2BOhIiSznLJK1eCJiEjwmNkY4F7ABzzqnPvrXvsvA+4CvvNvut8592iTBikizVLbxGhO6d2u3n3VNbXMX1/EZ8sKmLZsC49MW8lDH68gISqcYbnpDO2WzoCcZHq0TSBcCV+rFZIJXmlFNalxscEOQ0REQpCZ+YAHgNFAPjDTzKY45xbudejzzrnrmjxAEWmxwn1h9MtOpl92MtedlEtxeRWfL9/Kx0s2e4O4zN8IeBOwH52VRLc28XRJj6NrRjy5bePpkByjkTtbgdBM8CqriY8KyUsXEZHgGwQsd86tBDCz54BxwN4JnojIEUmIjmBMn3aM6dMO5xz523fy9drtzFm7g2/zd/Dm3A0U7qzafXxidDi9MhPp1T6JXpmJ9GyfQG6bBE0t1sKEZJZTVlFDrCY5FxGR4OgArKuzng8cV89x55jZCGApcKNzbl09x4iINIiZkZ0aS3ZqLOP6ddi9fVtpJSsLSli8sZiFG4pYsL6Ip2esoaK6FoDwMNtdw5fbJoEe7eLpnZlEVopq+5qrkEzwSiuriVMNnoiIBEd9fxG5vdZfB551zlWY2TXAk8BJ9Z7MbCIwESAnJ6cx4xSREJAaF0lqXCp5nVJ3b6updazaUsrCDUUs2lDE0o3FfJu/gzfmbth9TFJMBL0zE+mdmUjP9t7SNSNetX3NQMhlOTW1jvKqWtXgiYhIsOQD2XXWs4D1dQ9wzm2ts/oI8Lf9ncw5NwmYBJCXl7d3oigicsh8YUa3NvF0axPP2L6Zu7eXVVazdFMJC9YXMv+7IhasL+TJ6Wuo9Nf2+cKMtglRtEuKpn1SDL0yEzmxRxt6tk9QbV8TCrkEr6yyGoA4TZMgIiLBMRPINbPOeKNkTgAuqHuAmbV3zu36qnwssKhpQxQR2VdsZPjuQVx2qa6p3V3bt2xTCRsKy9lYtJOFG4p4c94G7npnCe2Tohmem06n9Dg6JMeQmRxDu8RoMhKiiI5QpUtjC7ksp6yyBoBYTZMgIiJB4JyrNrPrgHfwpkmY7JxbYGa3ArOcc1OA681sLFANbAMuC1rAIiIHEO4LI7dtArltE/bZt7monI+XFPDh4s28t3AT28uq9jkmITqcdonR9GiX4B/gJZGslBgSoyNIjIlQAngYQi7BK6nwavA0iqaIiASLc24qMHWvbbfUef1b4LdNHZeISGNqkxjNucdmc+6xXqv00opqNhTuJH/7TjYXV1DgX/K37+Sbdd/v47dLTISP7NQYclLj6JgWS+/MRAZ1TiUrRVOe7U9As5wGTOT6C+AqvG8oC4ArnHNrAhlTWYW/Bk9NNEVEREREmkxcVDjd2iTQrc2+tX0AhTurWLShiM3FFRTtrKJwZxXbSitZu62MtVvL+Gx5AeVVXn+/Dskx9MtJpl1iNGnxkaTFRZIcG0lSTARJMRGkxkWSER9FWFjo9f0LWJbTwIlc5wB5zrkyM7sWuBM4L1AxgTeCJkCcBlkREREREWk2kmIiGNwlbb/7a2sdSzYV89WqbXy1ahvz8gv5qGTz7i5Ye4sKDyM7NZac1FiyU2LITo0lKyWWzORoYiN9RIX7iAoPIyk2gqjw1pMbBLIa66ATuTrnPqpz/JfARQGMB9gzyEqsmmiKiIiIiLQYYWG2e0qGS4d22r19Z2UNW0oqKPTX+hXurGJrSYVX87etjDVby/hq1bbdXbXqkxoXSdvEaNolRpHpHwgmKyWG9PgokmO9GsHE6AgifGFE+KxZjwoayCynoRO57nIl8FYA4wGg1N9EUzV4IiIiIiItX0ykz5vE/QDHOOfYUVbFuu1lbCqqoLyqhorqWsqrathWWsnGonI2FZazobCcb9btqHdAmLp8YUZqXKSXCCbH0C4pmpTYCJJjI0mJjcQXZtTUOqpra/0/HbW1jhrn6NU+kf45KY17E+oIZILXkIlcvQPNLgLygJH72d9ok7iW+jN3TXQuIiIiIhIazIyUuEhS4iIbdHxZZTXrd5SztaSC7WWVbCutoqi8iuqaWqpqHFU1tWwtqWR94U4WbSjioyX7byq6t2tGdm2xCd5BJ3IFMLNRwO+Bkc65ivpO1JiTuJ7aux29MhNJj486ktOIiIiIiEgrFRsZvnuy94Yqr6qhcGcV28sqqa2FcJ/hCzN85v/pXwJd0RTIszdkItf+wL+BMc65zQGMZbdDydxFREREREQaIjrCR3SEj7aJ0UGNIyxQJ3bOVQO7JnJdBLywayJX/+StAHcB8cCLZvaNmU0JVDwiIiIiIiKtXUDrBxswkeuoQH6+iIiIiIhIKAlYDZ6IiIiIiIg0LSV4IiIiIiIirYQSPBERERERkVZCCZ6IiIiIiEgroQRPRERERESklVCCJyIiIiIi0koowRMREREREWkllOCJiIiIiIi0EuacC3YMh8TMCoA1h/HWdGCL/3USUFhnX931UNun+1L/Pt2XfV/XvSfNKa5g79N9qX/f3vflcHV0zmU0wnlCwmGWkXqG69+n+1L/Pt2X+vcF+r40p2s9lH36e6r+fY1RRu6/fHTOhcQCzKrzetJe+yaF8D7dF92XBu2re0+aU1zNYJ/uSwPui5bmu+gZ3u8+3Rfdl2ZzX5rZtR7KPv09dZD7EoglVJtovn6A9VDbt7/jghFLc9q3v+OCEUtz2tdc4wrmvr011ziDfV+k5Wiuz1Swn+HmGqfuS/PYt7fG/rzmdK2N8XdDMGJpTvsCqsU10TxcZjbLOZcX7DiaG92X+um+7Ev3pH66L/XTfWk59G9VP92X+um+1E/3pX66L/UL9H0JpRq8ScEOoJnSfamf7su+dE/qp/tSP92XlkP/VvXTfamf7kv9dF/qp/tSv4Del5CpwRMREREREWntQqkGT0REREREpFVr9QmemY0xsyVmttzM/i/Y8QSLmWWb2UdmtsjMFpjZz/3bU83sPTNb5v+ZEuxYg8HMfGY2x8ze8K93NrMZ/vvyvJlFBjvGpmZmyWb2kpkt9j83Q/S8gJnd6P8/NN/MnjWz6FB8XsxsspltNrP5dbbV+3yY5z7/7+G5ZjYgeJFLXSojPSoj90/l475UPtZP5aOnOZSPrTrBMzMf8ABwGtALON/MegU3qqCpBn7pnOsJDAZ+6r8X/wd84JzLBT7wr4einwOL6qz/Dfin/75sB64MSlTBdS/wtnPuKKAv3v0J6efFzDoA1wN5zrk+gA+YQGg+L08AY/batr/n4zQg179MBB5qohjlAFRGfo/KyP1T+bgvlY97Ufn4PU8Q5PKxVSd4wCBguXNupXOuEngOGBfkmILCObfBOfe1/3Ux3i+jDnj340n/YU8CPwhOhMFjZlnAGcCj/nUDTgJe8h8ScvfFzBKBEcBjAM65SufcDvS8AIQDMWYWDsQCGwjB58U5Nw3Yttfm/T0f44CnnOdLINnM2jdNpHIAKiP9VEbWT+XjvlQ+HpDKR5pH+djaE7wOwLo66/n+bSHNzDoB/YEZQFvn3AbwCjigTfAiC5p7gF8Dtf71NGCHc67avx6Kz00XoAB43N8051EziyPEnxfn3HfA3cBavIKrEJiNnpdd9vd86Hdx86R/l3qojPwelY/7UvlYD5WPB9Wk5WNrT/Csnm0hPWyomcUDLwM3OOeKgh1PsJnZmcBm59zsupvrOTTUnptwYADwkHOuP1BKiDU3qY+/zfw4oDOQCcThNa/YW6g9Lwej/1PNk/5d9qIycg+Vj/ul8rEeKh8PW0D+T7X2BC8fyK6zngWsD1IsQWdmEXgF19POuVf8mzftqgr2/9wcrPiC5HhgrJmtxmuedBLeN5bJ/iYGEJrPTT6Q75yb4V9/Ca9AC/XnZRSwyjlX4JyrAl4BhqLnZZf9PR/6Xdw86d+lDpWR+1D5WD+Vj/VT+XhgTVo+tvYEbyaQ6x/BJxKvs+eUIMcUFP52848Bi5xz/6izawpwqf/1pcBrTR1bMDnnfuucy3LOdcJ7Pj50zl0IfASM9x8WivdlI7DOzHr4N50MLCTEnxe8pieDzSzW/39q130J6eeljv09H1OAS/yjhQ0GCnc1VZGgUhnppzJyXyof66fycb9UPh5Yk5aPrX6iczM7He8bJx8w2Tl3R5BDCgozGwZ8CsxjT1v63+H1MXgByMH7z/kj59zeHUNDgpmdANzknDvTzLrgfWOZCswBLnLOVQQzvqZmZv3wOtZHAiuBy/G+FArp58XM/gSchzfq3hzgKrz28iH1vJjZs8AJQDqwCfgj8D/qeT78hf39eKOKlQGXO+dmBSNu+T6VkR6VkQem8vH7VD7WT+WjpzmUj60+wRMREREREQkVrb2JpoiIiIiISMhQgiciIiIiItJKKMETERERERFpJZTgiYiIiIiItBJK8ERERERERFoJJXgiTcjMaszsmzrL/zXiuTuZ2fzGOp+IiEhTUhkp0jjCD36IiDSinc65fsEOQkREpBlSGSnSCFSDJ9IMmNlqM/ubmX3lX7r5t3c0sw/MbK7/Z45/e1sze9XMvvUvQ/2n8pnZI2a2wMzeNbOYoF2UiIhII1AZKXJolOCJNK2YvZqfnFdnX5FzbhBwP3CPf9v9wFPOuWOAp4H7/NvvAz5xzvUFBgAL/NtzgQecc72BHcA5Ab4eERGRxqIyUqQRmHMu2DGIhAwzK3HOxdezfTVwknNupZlFABudc2lmtgVo75yr8m/f4JxLN7MCIMs5V1HnHJ2A95xzuf713wARzrnbA39lIiIiR0ZlpEjjUA2eSPPh9vN6f8fUp6LO6xrUz1ZERFoHlZEiDaQET6T5OK/Oz+n+118AE/yvLwQ+87/+ALgWwMx8ZpbYVEGKiIgEgcpIkQbSNxciTSvGzL6ps/62c27XMNBRZjYD74uX8/3brgcmm9mvgALgcv/2nwOTzOxKvG8hrwU2BDx6ERGRwFEZKdII1AdPpBnw9y/Ic85tCXYsIiIizYnKSJFDoyaaIiIiIiIirYRq8ERERERERFoJ1eCJiIiIiIi0EkrwREREREREWgkleCIiIiIiIq2EEjwREREREZFWQgmeiIiIiIhIK6EET0REREREpJX4/+LMTYO9ItStAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is: 87.73\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    def __init__(self, min_lr, max_lr, upramp=500, downramp=1000):\n",
    "        super().__init__()\n",
    "        self.rho = 0.85\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.currstep = 0\n",
    "        self.upramp = upramp\n",
    "        self.downramp = downramp\n",
    "        self.wt_decay = WT_DECAY\n",
    "        self.min_rho_multiplier = self.rho_multiplier = (1 - self.rho)/(self.wt_decay*max_lr)\n",
    "        self.max_val_acc = 0.0\n",
    "        self.max_val_acc_epoch = 0\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        currstep = self.currstep\n",
    "        upramp   = self.upramp\n",
    "        downramp = self.downramp\n",
    "        min_lr   = self.min_lr\n",
    "        max_lr   = self.max_lr\n",
    "        \n",
    "        dlr = self.max_lr - self.min_lr\n",
    "\n",
    "        if currstep < upramp :\n",
    "            dlr /= upramp\n",
    "            dlr = dlr*currstep\n",
    "        else:\n",
    "            dlr /= downramp\n",
    "            assert currstep <= (upramp + downramp)\n",
    "            dlr = dlr*(upramp + downramp - currstep)\n",
    "\n",
    "        if dlr < 0 :\n",
    "            dlr = 0.0\n",
    "            \n",
    "        self.lr = min_lr + dlr\n",
    "        \n",
    "        rho = 1 - self.rho_multiplier*self.lr*self.wt_decay\n",
    "        \n",
    "        if rho > 0:\n",
    "            self.rho = rho\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.lr)\n",
    "        #K.set_value(self.model.optimizer.momentum, self.rho)\n",
    "        \n",
    "        self.currstep += 1\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if self.currstep >= self.upramp + self.downramp:\n",
    "            self.currstep = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"lr: {0:.4f}, rho: {1:.4f}, wt_decay: {2:.4e}\".format(self.lr, self.rho, self.wt_decay))\n",
    "        \n",
    "        if epoch >= 9 and 2*logs.get('val_rloss') > logs.get('val_loss'):\n",
    "            print(\"Reducing weight decay by half...\")\n",
    "            #self.wt_decay /= 2\n",
    "            #K.set_value(self.model.l2_reg, self.wt_decay)\n",
    "        \n",
    "        val_acc = logs.get('val_acc')\n",
    "        \n",
    "        self.model.stop_training = self.model.stop_training or (val_acc > 0.9)\n",
    "        \n",
    "        if self.max_val_acc < val_acc:\n",
    "            self.max_val_acc = val_acc\n",
    "            self.max_val_acc_epoch = epoch\n",
    "            #if (self.rho_multiplier/2) >= self.min_rho_multiplier:\n",
    "                #print(\"Restoring momentum multiplier...\")\n",
    "                #self.rho_multiplier = self.min_rho_multiplier\n",
    "        #elif epoch - self.max_val_acc_epoch > 1:\n",
    "            #print(\"Increasing momentum multiplier by double...\")\n",
    "            #self.rho_multiplier *= 2\n",
    "\n",
    "steps_per_epoch = trainX.shape[0]//BATCH_SIZE+1\n",
    "\n",
    "clr = CyclicLR(1e-4, 0.08, 20*steps_per_epoch, 80*steps_per_epoch)\n",
    "\n",
    "mcp=ModelCheckpoint(\"model.{epoch:03d}-{val_acc:.4f}.hdf5\", \n",
    "                    monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Compile the model\n",
    "model = model_init()\n",
    "\n",
    "# train the model\n",
    "start = time.time()\n",
    "# Train the model\n",
    "model_info = model.fit_generator(datagen.flow(trainX, trainY, batch_size = BATCH_SIZE),\n",
    "                                 epochs=100, shuffle = True,\n",
    "                                 validation_data = (testX, testY), verbose=1,\n",
    "                                 callbacks=[mcp, clr, tensorboard_callback])\n",
    "end = time.time()\n",
    "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
    "# plot model history\n",
    "plot_model_history(model_info)\n",
    "# compute test accuracy\n",
    "print (\"Accuracy on test data is: %0.2f\"%accuracy(testX, testY, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
