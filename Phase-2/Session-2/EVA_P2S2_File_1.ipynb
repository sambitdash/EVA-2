{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA P2S2 File 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sambitdash/EVA-2/blob/master/Phase-2/Session-2/EVA_P2S2_File_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEliQmgpY_o7",
        "colab_type": "text"
      },
      "source": [
        "This is a reproduction of the IRNN experiment with pixel-by-pixel sequential MNIST in \"A Simple Way to Initialize Recurrent Networks of Rectified Linear Units\" by Quoc V. Le, Navdeep Jaitly, Geoffrey E. Hinton\n",
        "\n",
        "arxiv:1504.00941v2 [cs.NE] 7 Apr 2015 http://arxiv.org/pdf/1504.00941v2.pdf\n",
        "\n",
        "Optimizer is replaced with RMSprop which yields more stable and steady improvement.\n",
        "\n",
        "Reaches 0.93 train/test accuracy after 900 epochs (which roughly corresponds to 1687500 steps in the original paper.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFdvkq5J64uD",
        "colab_type": "text"
      },
      "source": [
        "# Phase 2 Session 2 File 1\n",
        "\n",
        "## Data Input Design\n",
        "\n",
        "The images are binary scanlines of $28\\times28$ images. Each scanline should be considered as image state that can be used for prediction. Hence, 28 scanlines are to be provided for the system to guess what will be final digit after 28 scanlines are read. \n",
        "\n",
        "The original code was forcing the image to a single state 768 size vector which had limited state information to learn. By keeping the image representation intact as $28\\times28$ improved the RNN cell vector correlations and thus better final prediction in just 10 epochs. \n",
        "\n",
        "Moreover, the batch sizes are reduced to 64 for frequent updates that can aid in faster update. Even learning rate can be increased to 1e-4 for faster convergence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_DJbE8-Wywp",
        "colab_type": "code",
        "outputId": "3ee9cf29-830c-43c3-e7b2-ef7778ce3572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import initializers\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "hidden_units = 100\n",
        "\n",
        "learning_rate = 1e-4\n",
        "clip_norm = 1.0\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "#x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgmyZ3Hz-N0j",
        "colab_type": "text"
      },
      "source": [
        "## Model Design\n",
        "\n",
        "The model is designed with 100 units and 28 states.\n",
        "\n",
        "Thus the total number of parameters are = 100*(100+28+1) = 12910 for RNN\n",
        "\n",
        "Dense layer of 100 to 10 with bias will have 1010 parameters\n",
        "\n",
        "Leading to 13910 parameters in total. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTqc6A5DzfDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1311780b-917c-4cd4-fc44-28522ea877b5"
      },
      "source": [
        "print('Evaluate IRNN...')\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(hidden_units, activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "rmsprop = RMSprop(lr=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=rmsprop,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate IRNN...\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_27 (SimpleRNN)    (None, 100)               12900     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,910\n",
            "Trainable params: 13,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anz0t-0BCKmA",
        "colab_type": "text"
      },
      "source": [
        "## Model Training\n",
        "\n",
        "The simple change of considering scanline as a state improves the convergence period and batch size can be reduced to 64 for faster updates. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzkbOAKSztrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "386f9896-8bc8-481b-dd42-12d10e2e0792"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('IRNN test score:', scores[0])\n",
        "print('IRNN test accuracy:', scores[1])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 20s 341us/step - loss: 1.2496 - acc: 0.5678 - val_loss: 0.6023 - val_acc: 0.8100\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 19s 309us/step - loss: 0.5100 - acc: 0.8416 - val_loss: 0.5403 - val_acc: 0.8315\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 19s 309us/step - loss: 0.3861 - acc: 0.8822 - val_loss: 0.3289 - val_acc: 0.9011\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 19s 312us/step - loss: 0.3245 - acc: 0.9031 - val_loss: 0.3083 - val_acc: 0.9101\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 19s 314us/step - loss: 0.2786 - acc: 0.9172 - val_loss: 0.3271 - val_acc: 0.8964\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 19s 309us/step - loss: 0.2480 - acc: 0.9272 - val_loss: 0.2356 - val_acc: 0.9298\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 19s 309us/step - loss: 0.2236 - acc: 0.9331 - val_loss: 0.2127 - val_acc: 0.9382\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 19s 309us/step - loss: 0.2054 - acc: 0.9391 - val_loss: 0.2005 - val_acc: 0.9413\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 18s 307us/step - loss: 0.1920 - acc: 0.9433 - val_loss: 0.1878 - val_acc: 0.9470\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 19s 310us/step - loss: 0.1803 - acc: 0.9472 - val_loss: 0.2037 - val_acc: 0.9391\n",
            "IRNN test score: 0.20373952242583038\n",
            "IRNN test accuracy: 0.9391\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}